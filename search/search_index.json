{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to OpenFaaS\n\n\n\n\nOpenFaaS (Functions as a Service) is a framework for building serverless functions with Docker which has first class support for metrics. Any process can be packaged as a function enabling you to consume a range of web events without repetitive boiler-plate coding.\n\n\nHighlights\n\n\n\n\nEase of use through UI portal and \none-click\n install\n\n\nWrite functions in any language for Linux or Windows and package in Docker/OCI image format\n\n\nPortable - runs on existing hardware or public/private cloud - \nKubernetes\n and Docker Swarm native\n\n\nCLI\n available with YAML format for templating and defining functions and featuring easy install via curl and brew\n\n\nAuto-scales as demand increases\n\n\nNew:\n Kubernetes support via \nFaaS-netes\n plugin\n\n\nNew:\n Windows function support\n\n\nNew:\n Asynchronous/long-running OpenFaaS functions via \nNATS Streaming\n - \nFollow this guide\n\n\n\n\nGovernance\n\n\nOpenFaaS is an independent project created by \nAlex Ellis\n which is now being built and shaped by a growing community of contributors. Project website: \nopenfaas.com\n.\n\n\nBackground\n\n\nThis is the original blog post from \n@alexellis\n on FaaS from January.\n\n\n\n\nFunctions as a Service blog post\n\n\n\n\nVideos\n\n\nSkillsMatter\n\n\nGreat introductory overview of OpenFaaS features, users and roadmap.\n\n\n\n\nHD Video\n\n\n\n\nOpenFaaS presents to CNCF Serverless workgroup\n\n\nThe OpenFaaS project had the pleasure of presenting OpenFaaS to the CNCF Serverless Workgroup.\n\n\n\n\nVideo and blog post\n\n\n\n\nDockercon 2017 Closing Keynote\n\n\nFunctions as a Service or FaaS was a winner in the Cool Hacks contest for Dockercon 2017.\n\n\n\n\nWatch Alex Ellis's OpenFaaS Keynote at Dockercon 2017\n\n\n\n\nIf you'd like to find the functions I used in the demos head over to the \nfaas-dockercon\n repository.", 
            "title": "Overview"
        }, 
        {
            "location": "/#welcome-to-openfaas", 
            "text": "OpenFaaS (Functions as a Service) is a framework for building serverless functions with Docker which has first class support for metrics. Any process can be packaged as a function enabling you to consume a range of web events without repetitive boiler-plate coding.", 
            "title": "Welcome to OpenFaaS"
        }, 
        {
            "location": "/#highlights", 
            "text": "Ease of use through UI portal and  one-click  install  Write functions in any language for Linux or Windows and package in Docker/OCI image format  Portable - runs on existing hardware or public/private cloud -  Kubernetes  and Docker Swarm native  CLI  available with YAML format for templating and defining functions and featuring easy install via curl and brew  Auto-scales as demand increases  New:  Kubernetes support via  FaaS-netes  plugin  New:  Windows function support  New:  Asynchronous/long-running OpenFaaS functions via  NATS Streaming  -  Follow this guide", 
            "title": "Highlights"
        }, 
        {
            "location": "/#governance", 
            "text": "OpenFaaS is an independent project created by  Alex Ellis  which is now being built and shaped by a growing community of contributors. Project website:  openfaas.com .", 
            "title": "Governance"
        }, 
        {
            "location": "/#background", 
            "text": "This is the original blog post from  @alexellis  on FaaS from January.   Functions as a Service blog post", 
            "title": "Background"
        }, 
        {
            "location": "/#videos", 
            "text": "", 
            "title": "Videos"
        }, 
        {
            "location": "/#skillsmatter", 
            "text": "Great introductory overview of OpenFaaS features, users and roadmap.   HD Video", 
            "title": "SkillsMatter"
        }, 
        {
            "location": "/#openfaas-presents-to-cncf-serverless-workgroup", 
            "text": "The OpenFaaS project had the pleasure of presenting OpenFaaS to the CNCF Serverless Workgroup.   Video and blog post", 
            "title": "OpenFaaS presents to CNCF Serverless workgroup"
        }, 
        {
            "location": "/#dockercon-2017-closing-keynote", 
            "text": "Functions as a Service or FaaS was a winner in the Cool Hacks contest for Dockercon 2017.   Watch Alex Ellis's OpenFaaS Keynote at Dockercon 2017   If you'd like to find the functions I used in the demos head over to the  faas-dockercon  repository.", 
            "title": "Dockercon 2017 Closing Keynote"
        }, 
        {
            "location": "/getting-started/deploy/", 
            "text": "Part 1 - Deploy OpenFaaS\n\n\nChoose an orchestrator\n\n\nBegin by choosing where you would like to deploy OpenFaaS.\n\n\n\n\nTip\n\n\nThe Docker Playground option lets you start a free remotely hosted OpenFaaS with a single click.\n\n\n\n\nDocker Swarm\n\n\nThe deployment guide for Docker Swarm provides a simple one-line command to get you up and running in around 60 seconds.\n\n\n\n\nDeployment guide for Docker Swarm\n\n\n\n\nKubernetes\n\n\nOpenFaaS is Kubernetes-native and provides a set of YAML configuration files to quickly deploy to a Kubernetes cluster.\n\n\n\n\nDeployment guide for Kubernetes\n\n\n\n\nDocker Playground\n\n\nThe community-run Docker playground: play-with-docker.com (PWD) allows you to start a free hosted Docker Swarm with OpenFaaS with a single click.\n\n\n\n\nDeployment guide for Play-with-Docker", 
            "title": "Part 1 - Deploy"
        }, 
        {
            "location": "/getting-started/deploy/#part-1-deploy-openfaas", 
            "text": "", 
            "title": "Part 1 - Deploy OpenFaaS"
        }, 
        {
            "location": "/getting-started/deploy/#choose-an-orchestrator", 
            "text": "Begin by choosing where you would like to deploy OpenFaaS.   Tip  The Docker Playground option lets you start a free remotely hosted OpenFaaS with a single click.   Docker Swarm  The deployment guide for Docker Swarm provides a simple one-line command to get you up and running in around 60 seconds.   Deployment guide for Docker Swarm   Kubernetes  OpenFaaS is Kubernetes-native and provides a set of YAML configuration files to quickly deploy to a Kubernetes cluster.   Deployment guide for Kubernetes   Docker Playground  The community-run Docker playground: play-with-docker.com (PWD) allows you to start a free hosted Docker Swarm with OpenFaaS with a single click.   Deployment guide for Play-with-Docker", 
            "title": "Choose an orchestrator"
        }, 
        {
            "location": "/getting-started/testdrive/", 
            "text": "OpenFaaS - TestDrive\n\n\nOpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.\n\n\n\n\nPlease support the project and put a \nStar\n on the repo.\n\n\n\n\nBegin the TestDrive\n\n\n\n\nBegin the TestDrive with Docker Swarm\n\n\n\n\nHere is a screenshot of the API gateway portal - designed for ease of use.\n\n\n\n\nOverview\n\n\nWe have provided several sample functions which are built-into the \nDocker Stack\n file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or \ncurl\n. When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:\n\n\n\n\nMorning coffee with the OpenFaaS CLI\n\n\n\n\nPre-reqs\n\n\nThe guide makes use of a cloud playground service called \nplay-with-docker.com\n that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.\n\n\nBackground info:\n\n\n\n\nThere is also a \nblog post\n that goes into the background of the project.\n\n\n\n\nStart here\n\n\n\n\n\n\nSo let's head over to \nhttp://play-with-docker.com/\n and start a new session. You will probably have to fill out a Captcha.\n\n\n\n\n\n\nClick \"Add New Instance\" to create a single Docker host (more can be added later)\n\n\n\n\n\n\nThis one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:\n\n\n# docker swarm init --advertise-addr eth0 \n \\\n  git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  git checkout 0.6.6-beta1 \n \\\n  ./deploy_stack.sh \n \\\n  docker service ls\n\n\n\n\nThe shell script makes use of a v3 docker-compose.yml file - read the \ndeploy_stack.sh\n file for more details.\n\n\n\n\nIf you are not testing on play-with-docker then remove \n--advertise-addr eth0\n from first line of the script.\n\n\n\n\n\n\n\n\nNow that everything's deployed take note of the two ports at the top of the screen:\n\n\n\n\n\n\n8080 - the API Gateway and OpenFaaS UI\n\n\n\n\n9090 - the Prometheus metrics endpoint\n\n\n\n\n\n\nInstall FaaS-CLI\n\n\nWe will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.\n\n\n$ curl -sL cli.openfaas.com \n|\n sh\n\n\n\n\nOn your own machine change \n| sh\n to \n| sudo sh\n, for MacOS you can just use \nbrew install faas-cli\n.\n\n\n\n\nFind out what you can do\n\n\n\n\n$ faas-cli --help\n\n\n\n\nInvoke the sample functions with curl or Postman:\n\n\nHead over to the \nGithub and Star the project\n, or read on to see the input/output from the sample functions.\n\n\nWorking with the sample functions\n\n\nYou can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.\n\n\n\n\nInvoke the markdown function with the CLI:\n\n\n\n\n$ echo \n# Test *Drive*\n| faas-cli invoke func_markdown\n\nh1\nTest \nem\nDrive\n/em\n/h1\n\n\n\n\n\n\n\nList your functions\n\n\n\n\n$ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1\n\n\n\n\nUI portal:\n\n\nThe UI portal is accessible on: \nhttp://localhost:8080/\n - it show a list of functions deployed on your swarm and allows you to test them out.\n\n\nView screenshot:\n\n\n\n\nYou can find out which services are deployed like this:\n\n\n# docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago\n\n\n\n\n\n\nHead over to \nhttp://localhost:9090\n for your Prometheus metrics\n\n\n\n\nA saved Prometheus view is available here: \nmetrics overview\n\n\n\n\n\n\nYour functions can be accessed via the gateway UI or read on for \ncurl\n\n\n\n\n\n\nBuild functions from templates and the CLI\n\n\nThe following guides show how to use the CLI and code templates to build functions.\n\n\nUsing a template means you only have to write a handler file in your chosen programming language such as:\n\n\n\n\nRuby\n\n\nNode.js\n\n\nPython\n\n\nCSharp\n\n\nOr propose a template for another programming languae\n\n\n\n\nGuides:\n\n\n\n\n\n\nYour first serverless Python function with OpenFaaS\n\n\n\n\n\n\nYour first serverless .NET / C# function with OpenFaaS\n\n\n\n\n\n\nPackage a custom Docker image\n\n\nRead the developer guide:\n\n\n\n\nPackaging a function\n\n\n\n\nThe original blog post also walks through creating a function:\n\n\n\n\nFaaS blog post\n\n\n\n\nAdd new functions to FaaS at runtime\n\n\nOption 1: via the FaaS CLI\n\n\nThe FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI \nhere\n.\n\n\nOption 2: via FaaS UI portal\n\n\nTo attach a function at runtime you can use the \"Create New Function\" button on the portal UI at \nhttp://localhost:8080/\n \n\n\n\n\nCreating a function via the UI:\n\n\n\n\n\n\n\n\nOption\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nImage\n\n\nThe name of the image you want to use for the function. A good starting point is functions/alpine\n\n\n\n\n\n\nService Name\n\n\nDescribe the name of your service. The Service Name format is: [a-zA-Z_0-9]\n\n\n\n\n\n\nfProcess\n\n\nThe process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.\n\n\n\n\n\n\nNetwork\n\n\nThe network \nfunc_functions\n is the default network.\n\n\n\n\n\n\n\n\nOnce the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.\n\n\nOption 3: Through docker-compose.yml stack file\n \n\n\nEdit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.\n\n\nOption 4: Programatically through a HTTP POST to the API Gateway\n\n\nA HTTP post can also be sent via \ncurl\n etc to the endpoint used by the UI (HTTP post to \n/system/functions\n)\n\n\n// CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json:\nservice\n`\n    Image      string `json:\nimage\n`\n    Network    string `json:\nnetwork\n`\n    EnvProcess string `json:\nenvProcess\n`\n}\n\n\n\n\nExample:\n\n\nFor a quote-of-the-day type of application:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \noblique\n, \nimage\n: \nvielmetti/faas-oblique\n, \nenvProcess\n: \n/usr/bin/oblique\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nFor a hashing algorithm:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \nstronghash\n, \nimage\n: \nfunctions/alpine\n, \nenvProcess\n: \nsha512sum\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nDelete a function at runtime\n\n\nYou can delete a function through the FaaS-CLI or with the Docker CLI\n\n\n$ docker service rm func_echoit\n\n\n\n\nExploring the functions with \ncurl\n\n\nSample function: Docker Hub Stats (hubstats)\n\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nalexellis2\n\nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nlibrary\n\nThe organisation or user library has 128 repositories on the Docker hub.\n\n\n\n\nThe \n-d\n value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.\n\n\nSample function: Node OS Info (nodeinfo)\n\n\nGrab OS, CPU and other info via a Node.js container using the \nos\n module.\n\n\nIf you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.\n\n\nHere is a loop that can be used to invoke the function in a loop to trigger auto-scaling.\n\nwhile [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d \n; done\n\n\n\nExample:\n\n\n# curl -X POST http://localhost:8080/function/func_nodeinfo -d \n\n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839\n\n\n\n\nSample function: webhook stasher (webhookstash)\n\n\nAnother cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.\n\n\n# curl -X POST http://localhost:8080/function/func_webhookstash -d \n{\nevent\n: \nfork\n, \nrepo\n: \nalexellis2/faas\n}\n\nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt\n\n\n\n\n\n\nWhy not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Part 2 - OpenFaaS CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#openfaas-testdrive", 
            "text": "OpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.   Please support the project and put a  Star  on the repo.", 
            "title": "OpenFaaS - TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#begin-the-testdrive", 
            "text": "Begin the TestDrive with Docker Swarm   Here is a screenshot of the API gateway portal - designed for ease of use.", 
            "title": "Begin the TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#overview", 
            "text": "We have provided several sample functions which are built-into the  Docker Stack  file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or  curl . When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:   Morning coffee with the OpenFaaS CLI", 
            "title": "Overview"
        }, 
        {
            "location": "/getting-started/testdrive/#pre-reqs", 
            "text": "The guide makes use of a cloud playground service called  play-with-docker.com  that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.  Background info:   There is also a  blog post  that goes into the background of the project.", 
            "title": "Pre-reqs"
        }, 
        {
            "location": "/getting-started/testdrive/#start-here", 
            "text": "So let's head over to  http://play-with-docker.com/  and start a new session. You will probably have to fill out a Captcha.    Click \"Add New Instance\" to create a single Docker host (more can be added later)    This one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:  # docker swarm init --advertise-addr eth0   \\\n  git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  git checkout 0.6.6-beta1   \\\n  ./deploy_stack.sh   \\\n  docker service ls  The shell script makes use of a v3 docker-compose.yml file - read the  deploy_stack.sh  file for more details.   If you are not testing on play-with-docker then remove  --advertise-addr eth0  from first line of the script.     Now that everything's deployed take note of the two ports at the top of the screen:    8080 - the API Gateway and OpenFaaS UI   9090 - the Prometheus metrics endpoint", 
            "title": "Start here"
        }, 
        {
            "location": "/getting-started/testdrive/#install-faas-cli", 
            "text": "We will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.  $ curl -sL cli.openfaas.com  |  sh  On your own machine change  | sh  to  | sudo sh , for MacOS you can just use  brew install faas-cli .   Find out what you can do   $ faas-cli --help", 
            "title": "Install FaaS-CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#invoke-the-sample-functions-with-curl-or-postman", 
            "text": "Head over to the  Github and Star the project , or read on to see the input/output from the sample functions.", 
            "title": "Invoke the sample functions with curl or Postman:"
        }, 
        {
            "location": "/getting-started/testdrive/#working-with-the-sample-functions", 
            "text": "You can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.   Invoke the markdown function with the CLI:   $ echo  # Test *Drive* | faas-cli invoke func_markdown h1 Test  em Drive /em /h1    List your functions   $ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1  UI portal:  The UI portal is accessible on:  http://localhost:8080/  - it show a list of functions deployed on your swarm and allows you to test them out.  View screenshot:   You can find out which services are deployed like this:  # docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago   Head over to  http://localhost:9090  for your Prometheus metrics   A saved Prometheus view is available here:  metrics overview    Your functions can be accessed via the gateway UI or read on for  curl", 
            "title": "Working with the sample functions"
        }, 
        {
            "location": "/getting-started/testdrive/#build-functions-from-templates-and-the-cli", 
            "text": "The following guides show how to use the CLI and code templates to build functions.  Using a template means you only have to write a handler file in your chosen programming language such as:   Ruby  Node.js  Python  CSharp  Or propose a template for another programming languae   Guides:    Your first serverless Python function with OpenFaaS    Your first serverless .NET / C# function with OpenFaaS", 
            "title": "Build functions from templates and the CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#package-a-custom-docker-image", 
            "text": "Read the developer guide:   Packaging a function   The original blog post also walks through creating a function:   FaaS blog post", 
            "title": "Package a custom Docker image"
        }, 
        {
            "location": "/getting-started/testdrive/#add-new-functions-to-faas-at-runtime", 
            "text": "Option 1: via the FaaS CLI  The FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI  here .  Option 2: via FaaS UI portal  To attach a function at runtime you can use the \"Create New Function\" button on the portal UI at  http://localhost:8080/     Creating a function via the UI:     Option  Usage      Image  The name of the image you want to use for the function. A good starting point is functions/alpine    Service Name  Describe the name of your service. The Service Name format is: [a-zA-Z_0-9]    fProcess  The process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.    Network  The network  func_functions  is the default network.     Once the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.  Option 3: Through docker-compose.yml stack file    Edit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.  Option 4: Programatically through a HTTP POST to the API Gateway  A HTTP post can also be sent via  curl  etc to the endpoint used by the UI (HTTP post to  /system/functions )  // CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json: service `\n    Image      string `json: image `\n    Network    string `json: network `\n    EnvProcess string `json: envProcess `\n}  Example:  For a quote-of-the-day type of application:  curl localhost:8080/system/functions -d  \n{ service :  oblique ,  image :  vielmetti/faas-oblique ,  envProcess :  /usr/bin/oblique ,  network :  func_functions }   For a hashing algorithm:  curl localhost:8080/system/functions -d  \n{ service :  stronghash ,  image :  functions/alpine ,  envProcess :  sha512sum ,  network :  func_functions }", 
            "title": "Add new functions to FaaS at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#delete-a-function-at-runtime", 
            "text": "You can delete a function through the FaaS-CLI or with the Docker CLI  $ docker service rm func_echoit", 
            "title": "Delete a function at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#exploring-the-functions-with-curl", 
            "text": "Sample function: Docker Hub Stats (hubstats)  # curl -X POST http://localhost:8080/function/func_hubstats -d  alexellis2 \nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d  library \nThe organisation or user library has 128 repositories on the Docker hub.  The  -d  value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.  Sample function: Node OS Info (nodeinfo)  Grab OS, CPU and other info via a Node.js container using the  os  module.  If you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.  Here is a loop that can be used to invoke the function in a loop to trigger auto-scaling. while [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d  ; done  Example:  # curl -X POST http://localhost:8080/function/func_nodeinfo -d  \n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839  Sample function: webhook stasher (webhookstash)  Another cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.  # curl -X POST http://localhost:8080/function/func_webhookstash -d  { event :  fork ,  repo :  alexellis2/faas } \nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt   Why not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Exploring the functions with curl"
        }, 
        {
            "location": "/getting-started/sample_functions/", 
            "text": "Sample functions\n\n\nWe have packaged some simple starter functions in the Docker stack when deployed on Swarm, so as soon as you open the OpenFaaS UI you will see them listed down the left-hand side.\n\n\nHere are a few of the functions:\n\n\n\n\nEcho function (echoit) - echos any received text back to the caller (wraps Linux \ncat\n binary)\n\n\nMarkdown to HTML renderer (markdownrender) - takes .MD input and produces HTML (Golang)\n\n\nDocker Hub Stats function (hubstats) - queries the count of images for a user on the Docker Hub (Golang)\n\n\nNode Info (nodeinfo) function - gives you the OS architecture and detailled info about the CPUS (Node.js)\n\n\nWebhook stasher function (webhookstash) - saves webhook body into container's filesystem - even binaries (Golang)\n\n\n\n\n\n\n\nYou can now grab a coffee and start learning how to create your first function with the CLI:\n\n\nMorning coffee with the OpenFaaS CLI", 
            "title": "Part 3 - Sample Functions"
        }, 
        {
            "location": "/getting-started/sample_functions/#sample-functions", 
            "text": "We have packaged some simple starter functions in the Docker stack when deployed on Swarm, so as soon as you open the OpenFaaS UI you will see them listed down the left-hand side.  Here are a few of the functions:   Echo function (echoit) - echos any received text back to the caller (wraps Linux  cat  binary)  Markdown to HTML renderer (markdownrender) - takes .MD input and produces HTML (Golang)  Docker Hub Stats function (hubstats) - queries the count of images for a user on the Docker Hub (Golang)  Node Info (nodeinfo) function - gives you the OS architecture and detailled info about the CPUS (Node.js)  Webhook stasher function (webhookstash) - saves webhook body into container's filesystem - even binaries (Golang)    You can now grab a coffee and start learning how to create your first function with the CLI:  Morning coffee with the OpenFaaS CLI", 
            "title": "Sample functions"
        }, 
        {
            "location": "/getting-started/testdrive/", 
            "text": "OpenFaaS - TestDrive\n\n\nOpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.\n\n\n\n\nPlease support the project and put a \nStar\n on the repo.\n\n\n\n\nBegin the TestDrive\n\n\n\n\nBegin the TestDrive with Docker Swarm\n\n\n\n\nHere is a screenshot of the API gateway portal - designed for ease of use.\n\n\n\n\nOverview\n\n\nWe have provided several sample functions which are built-into the \nDocker Stack\n file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or \ncurl\n. When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:\n\n\n\n\nMorning coffee with the OpenFaaS CLI\n\n\n\n\nPre-reqs\n\n\nThe guide makes use of a cloud playground service called \nplay-with-docker.com\n that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.\n\n\nBackground info:\n\n\n\n\nThere is also a \nblog post\n that goes into the background of the project.\n\n\n\n\nStart here\n\n\n\n\n\n\nSo let's head over to \nhttp://play-with-docker.com/\n and start a new session. You will probably have to fill out a Captcha.\n\n\n\n\n\n\nClick \"Add New Instance\" to create a single Docker host (more can be added later)\n\n\n\n\n\n\nThis one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:\n\n\n# docker swarm init --advertise-addr eth0 \n \\\n  git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  git checkout 0.6.6-beta1 \n \\\n  ./deploy_stack.sh \n \\\n  docker service ls\n\n\n\n\nThe shell script makes use of a v3 docker-compose.yml file - read the \ndeploy_stack.sh\n file for more details.\n\n\n\n\nIf you are not testing on play-with-docker then remove \n--advertise-addr eth0\n from first line of the script.\n\n\n\n\n\n\n\n\nNow that everything's deployed take note of the two ports at the top of the screen:\n\n\n\n\n\n\n8080 - the API Gateway and OpenFaaS UI\n\n\n\n\n9090 - the Prometheus metrics endpoint\n\n\n\n\n\n\nInstall FaaS-CLI\n\n\nWe will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.\n\n\n$ curl -sL cli.openfaas.com \n|\n sh\n\n\n\n\nOn your own machine change \n| sh\n to \n| sudo sh\n, for MacOS you can just use \nbrew install faas-cli\n.\n\n\n\n\nFind out what you can do\n\n\n\n\n$ faas-cli --help\n\n\n\n\nInvoke the sample functions with curl or Postman:\n\n\nHead over to the \nGithub and Star the project\n, or read on to see the input/output from the sample functions.\n\n\nWorking with the sample functions\n\n\nYou can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.\n\n\n\n\nInvoke the markdown function with the CLI:\n\n\n\n\n$ echo \n# Test *Drive*\n| faas-cli invoke func_markdown\n\nh1\nTest \nem\nDrive\n/em\n/h1\n\n\n\n\n\n\n\nList your functions\n\n\n\n\n$ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1\n\n\n\n\nUI portal:\n\n\nThe UI portal is accessible on: \nhttp://localhost:8080/\n - it show a list of functions deployed on your swarm and allows you to test them out.\n\n\nView screenshot:\n\n\n\n\nYou can find out which services are deployed like this:\n\n\n# docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago\n\n\n\n\n\n\nHead over to \nhttp://localhost:9090\n for your Prometheus metrics\n\n\n\n\nA saved Prometheus view is available here: \nmetrics overview\n\n\n\n\n\n\nYour functions can be accessed via the gateway UI or read on for \ncurl\n\n\n\n\n\n\nBuild functions from templates and the CLI\n\n\nThe following guides show how to use the CLI and code templates to build functions.\n\n\nUsing a template means you only have to write a handler file in your chosen programming language such as:\n\n\n\n\nRuby\n\n\nNode.js\n\n\nPython\n\n\nCSharp\n\n\nOr propose a template for another programming languae\n\n\n\n\nGuides:\n\n\n\n\n\n\nYour first serverless Python function with OpenFaaS\n\n\n\n\n\n\nYour first serverless .NET / C# function with OpenFaaS\n\n\n\n\n\n\nPackage a custom Docker image\n\n\nRead the developer guide:\n\n\n\n\nPackaging a function\n\n\n\n\nThe original blog post also walks through creating a function:\n\n\n\n\nFaaS blog post\n\n\n\n\nAdd new functions to FaaS at runtime\n\n\nOption 1: via the FaaS CLI\n\n\nThe FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI \nhere\n.\n\n\nOption 2: via FaaS UI portal\n\n\nTo attach a function at runtime you can use the \"Create New Function\" button on the portal UI at \nhttp://localhost:8080/\n \n\n\n\n\nCreating a function via the UI:\n\n\n\n\n\n\n\n\nOption\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nImage\n\n\nThe name of the image you want to use for the function. A good starting point is functions/alpine\n\n\n\n\n\n\nService Name\n\n\nDescribe the name of your service. The Service Name format is: [a-zA-Z_0-9]\n\n\n\n\n\n\nfProcess\n\n\nThe process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.\n\n\n\n\n\n\nNetwork\n\n\nThe network \nfunc_functions\n is the default network.\n\n\n\n\n\n\n\n\nOnce the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.\n\n\nOption 3: Through docker-compose.yml stack file\n \n\n\nEdit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.\n\n\nOption 4: Programatically through a HTTP POST to the API Gateway\n\n\nA HTTP post can also be sent via \ncurl\n etc to the endpoint used by the UI (HTTP post to \n/system/functions\n)\n\n\n// CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json:\nservice\n`\n    Image      string `json:\nimage\n`\n    Network    string `json:\nnetwork\n`\n    EnvProcess string `json:\nenvProcess\n`\n}\n\n\n\n\nExample:\n\n\nFor a quote-of-the-day type of application:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \noblique\n, \nimage\n: \nvielmetti/faas-oblique\n, \nenvProcess\n: \n/usr/bin/oblique\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nFor a hashing algorithm:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \nstronghash\n, \nimage\n: \nfunctions/alpine\n, \nenvProcess\n: \nsha512sum\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nDelete a function at runtime\n\n\nYou can delete a function through the FaaS-CLI or with the Docker CLI\n\n\n$ docker service rm func_echoit\n\n\n\n\nExploring the functions with \ncurl\n\n\nSample function: Docker Hub Stats (hubstats)\n\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nalexellis2\n\nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nlibrary\n\nThe organisation or user library has 128 repositories on the Docker hub.\n\n\n\n\nThe \n-d\n value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.\n\n\nSample function: Node OS Info (nodeinfo)\n\n\nGrab OS, CPU and other info via a Node.js container using the \nos\n module.\n\n\nIf you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.\n\n\nHere is a loop that can be used to invoke the function in a loop to trigger auto-scaling.\n\nwhile [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d \n; done\n\n\n\nExample:\n\n\n# curl -X POST http://localhost:8080/function/func_nodeinfo -d \n\n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839\n\n\n\n\nSample function: webhook stasher (webhookstash)\n\n\nAnother cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.\n\n\n# curl -X POST http://localhost:8080/function/func_webhookstash -d \n{\nevent\n: \nfork\n, \nrepo\n: \nalexellis2/faas\n}\n\nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt\n\n\n\n\n\n\nWhy not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Part 4 - Create a Function"
        }, 
        {
            "location": "/getting-started/testdrive/#openfaas-testdrive", 
            "text": "OpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.   Please support the project and put a  Star  on the repo.", 
            "title": "OpenFaaS - TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#begin-the-testdrive", 
            "text": "Begin the TestDrive with Docker Swarm   Here is a screenshot of the API gateway portal - designed for ease of use.", 
            "title": "Begin the TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#overview", 
            "text": "We have provided several sample functions which are built-into the  Docker Stack  file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or  curl . When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:   Morning coffee with the OpenFaaS CLI", 
            "title": "Overview"
        }, 
        {
            "location": "/getting-started/testdrive/#pre-reqs", 
            "text": "The guide makes use of a cloud playground service called  play-with-docker.com  that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.  Background info:   There is also a  blog post  that goes into the background of the project.", 
            "title": "Pre-reqs"
        }, 
        {
            "location": "/getting-started/testdrive/#start-here", 
            "text": "So let's head over to  http://play-with-docker.com/  and start a new session. You will probably have to fill out a Captcha.    Click \"Add New Instance\" to create a single Docker host (more can be added later)    This one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:  # docker swarm init --advertise-addr eth0   \\\n  git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  git checkout 0.6.6-beta1   \\\n  ./deploy_stack.sh   \\\n  docker service ls  The shell script makes use of a v3 docker-compose.yml file - read the  deploy_stack.sh  file for more details.   If you are not testing on play-with-docker then remove  --advertise-addr eth0  from first line of the script.     Now that everything's deployed take note of the two ports at the top of the screen:    8080 - the API Gateway and OpenFaaS UI   9090 - the Prometheus metrics endpoint", 
            "title": "Start here"
        }, 
        {
            "location": "/getting-started/testdrive/#install-faas-cli", 
            "text": "We will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.  $ curl -sL cli.openfaas.com  |  sh  On your own machine change  | sh  to  | sudo sh , for MacOS you can just use  brew install faas-cli .   Find out what you can do   $ faas-cli --help", 
            "title": "Install FaaS-CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#invoke-the-sample-functions-with-curl-or-postman", 
            "text": "Head over to the  Github and Star the project , or read on to see the input/output from the sample functions.", 
            "title": "Invoke the sample functions with curl or Postman:"
        }, 
        {
            "location": "/getting-started/testdrive/#working-with-the-sample-functions", 
            "text": "You can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.   Invoke the markdown function with the CLI:   $ echo  # Test *Drive* | faas-cli invoke func_markdown h1 Test  em Drive /em /h1    List your functions   $ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1  UI portal:  The UI portal is accessible on:  http://localhost:8080/  - it show a list of functions deployed on your swarm and allows you to test them out.  View screenshot:   You can find out which services are deployed like this:  # docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago   Head over to  http://localhost:9090  for your Prometheus metrics   A saved Prometheus view is available here:  metrics overview    Your functions can be accessed via the gateway UI or read on for  curl", 
            "title": "Working with the sample functions"
        }, 
        {
            "location": "/getting-started/testdrive/#build-functions-from-templates-and-the-cli", 
            "text": "The following guides show how to use the CLI and code templates to build functions.  Using a template means you only have to write a handler file in your chosen programming language such as:   Ruby  Node.js  Python  CSharp  Or propose a template for another programming languae   Guides:    Your first serverless Python function with OpenFaaS    Your first serverless .NET / C# function with OpenFaaS", 
            "title": "Build functions from templates and the CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#package-a-custom-docker-image", 
            "text": "Read the developer guide:   Packaging a function   The original blog post also walks through creating a function:   FaaS blog post", 
            "title": "Package a custom Docker image"
        }, 
        {
            "location": "/getting-started/testdrive/#add-new-functions-to-faas-at-runtime", 
            "text": "Option 1: via the FaaS CLI  The FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI  here .  Option 2: via FaaS UI portal  To attach a function at runtime you can use the \"Create New Function\" button on the portal UI at  http://localhost:8080/     Creating a function via the UI:     Option  Usage      Image  The name of the image you want to use for the function. A good starting point is functions/alpine    Service Name  Describe the name of your service. The Service Name format is: [a-zA-Z_0-9]    fProcess  The process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.    Network  The network  func_functions  is the default network.     Once the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.  Option 3: Through docker-compose.yml stack file    Edit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.  Option 4: Programatically through a HTTP POST to the API Gateway  A HTTP post can also be sent via  curl  etc to the endpoint used by the UI (HTTP post to  /system/functions )  // CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json: service `\n    Image      string `json: image `\n    Network    string `json: network `\n    EnvProcess string `json: envProcess `\n}  Example:  For a quote-of-the-day type of application:  curl localhost:8080/system/functions -d  \n{ service :  oblique ,  image :  vielmetti/faas-oblique ,  envProcess :  /usr/bin/oblique ,  network :  func_functions }   For a hashing algorithm:  curl localhost:8080/system/functions -d  \n{ service :  stronghash ,  image :  functions/alpine ,  envProcess :  sha512sum ,  network :  func_functions }", 
            "title": "Add new functions to FaaS at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#delete-a-function-at-runtime", 
            "text": "You can delete a function through the FaaS-CLI or with the Docker CLI  $ docker service rm func_echoit", 
            "title": "Delete a function at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#exploring-the-functions-with-curl", 
            "text": "Sample function: Docker Hub Stats (hubstats)  # curl -X POST http://localhost:8080/function/func_hubstats -d  alexellis2 \nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d  library \nThe organisation or user library has 128 repositories on the Docker hub.  The  -d  value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.  Sample function: Node OS Info (nodeinfo)  Grab OS, CPU and other info via a Node.js container using the  os  module.  If you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.  Here is a loop that can be used to invoke the function in a loop to trigger auto-scaling. while [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d  ; done  Example:  # curl -X POST http://localhost:8080/function/func_nodeinfo -d  \n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839  Sample function: webhook stasher (webhookstash)  Another cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.  # curl -X POST http://localhost:8080/function/func_webhookstash -d  { event :  fork ,  repo :  alexellis2/faas } \nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt   Why not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Exploring the functions with curl"
        }, 
        {
            "location": "/getting-started/testdrive/", 
            "text": "OpenFaaS - TestDrive\n\n\nOpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.\n\n\n\n\nPlease support the project and put a \nStar\n on the repo.\n\n\n\n\nBegin the TestDrive\n\n\n\n\nBegin the TestDrive with Docker Swarm\n\n\n\n\nHere is a screenshot of the API gateway portal - designed for ease of use.\n\n\n\n\nOverview\n\n\nWe have provided several sample functions which are built-into the \nDocker Stack\n file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or \ncurl\n. When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:\n\n\n\n\nMorning coffee with the OpenFaaS CLI\n\n\n\n\nPre-reqs\n\n\nThe guide makes use of a cloud playground service called \nplay-with-docker.com\n that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.\n\n\nBackground info:\n\n\n\n\nThere is also a \nblog post\n that goes into the background of the project.\n\n\n\n\nStart here\n\n\n\n\n\n\nSo let's head over to \nhttp://play-with-docker.com/\n and start a new session. You will probably have to fill out a Captcha.\n\n\n\n\n\n\nClick \"Add New Instance\" to create a single Docker host (more can be added later)\n\n\n\n\n\n\nThis one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:\n\n\n# docker swarm init --advertise-addr eth0 \n \\\n  git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  git checkout 0.6.6-beta1 \n \\\n  ./deploy_stack.sh \n \\\n  docker service ls\n\n\n\n\nThe shell script makes use of a v3 docker-compose.yml file - read the \ndeploy_stack.sh\n file for more details.\n\n\n\n\nIf you are not testing on play-with-docker then remove \n--advertise-addr eth0\n from first line of the script.\n\n\n\n\n\n\n\n\nNow that everything's deployed take note of the two ports at the top of the screen:\n\n\n\n\n\n\n8080 - the API Gateway and OpenFaaS UI\n\n\n\n\n9090 - the Prometheus metrics endpoint\n\n\n\n\n\n\nInstall FaaS-CLI\n\n\nWe will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.\n\n\n$ curl -sL cli.openfaas.com \n|\n sh\n\n\n\n\nOn your own machine change \n| sh\n to \n| sudo sh\n, for MacOS you can just use \nbrew install faas-cli\n.\n\n\n\n\nFind out what you can do\n\n\n\n\n$ faas-cli --help\n\n\n\n\nInvoke the sample functions with curl or Postman:\n\n\nHead over to the \nGithub and Star the project\n, or read on to see the input/output from the sample functions.\n\n\nWorking with the sample functions\n\n\nYou can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.\n\n\n\n\nInvoke the markdown function with the CLI:\n\n\n\n\n$ echo \n# Test *Drive*\n| faas-cli invoke func_markdown\n\nh1\nTest \nem\nDrive\n/em\n/h1\n\n\n\n\n\n\n\nList your functions\n\n\n\n\n$ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1\n\n\n\n\nUI portal:\n\n\nThe UI portal is accessible on: \nhttp://localhost:8080/\n - it show a list of functions deployed on your swarm and allows you to test them out.\n\n\nView screenshot:\n\n\n\n\nYou can find out which services are deployed like this:\n\n\n# docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago\n\n\n\n\n\n\nHead over to \nhttp://localhost:9090\n for your Prometheus metrics\n\n\n\n\nA saved Prometheus view is available here: \nmetrics overview\n\n\n\n\n\n\nYour functions can be accessed via the gateway UI or read on for \ncurl\n\n\n\n\n\n\nBuild functions from templates and the CLI\n\n\nThe following guides show how to use the CLI and code templates to build functions.\n\n\nUsing a template means you only have to write a handler file in your chosen programming language such as:\n\n\n\n\nRuby\n\n\nNode.js\n\n\nPython\n\n\nCSharp\n\n\nOr propose a template for another programming languae\n\n\n\n\nGuides:\n\n\n\n\n\n\nYour first serverless Python function with OpenFaaS\n\n\n\n\n\n\nYour first serverless .NET / C# function with OpenFaaS\n\n\n\n\n\n\nPackage a custom Docker image\n\n\nRead the developer guide:\n\n\n\n\nPackaging a function\n\n\n\n\nThe original blog post also walks through creating a function:\n\n\n\n\nFaaS blog post\n\n\n\n\nAdd new functions to FaaS at runtime\n\n\nOption 1: via the FaaS CLI\n\n\nThe FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI \nhere\n.\n\n\nOption 2: via FaaS UI portal\n\n\nTo attach a function at runtime you can use the \"Create New Function\" button on the portal UI at \nhttp://localhost:8080/\n \n\n\n\n\nCreating a function via the UI:\n\n\n\n\n\n\n\n\nOption\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nImage\n\n\nThe name of the image you want to use for the function. A good starting point is functions/alpine\n\n\n\n\n\n\nService Name\n\n\nDescribe the name of your service. The Service Name format is: [a-zA-Z_0-9]\n\n\n\n\n\n\nfProcess\n\n\nThe process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.\n\n\n\n\n\n\nNetwork\n\n\nThe network \nfunc_functions\n is the default network.\n\n\n\n\n\n\n\n\nOnce the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.\n\n\nOption 3: Through docker-compose.yml stack file\n \n\n\nEdit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.\n\n\nOption 4: Programatically through a HTTP POST to the API Gateway\n\n\nA HTTP post can also be sent via \ncurl\n etc to the endpoint used by the UI (HTTP post to \n/system/functions\n)\n\n\n// CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json:\nservice\n`\n    Image      string `json:\nimage\n`\n    Network    string `json:\nnetwork\n`\n    EnvProcess string `json:\nenvProcess\n`\n}\n\n\n\n\nExample:\n\n\nFor a quote-of-the-day type of application:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \noblique\n, \nimage\n: \nvielmetti/faas-oblique\n, \nenvProcess\n: \n/usr/bin/oblique\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nFor a hashing algorithm:\n\n\ncurl localhost:8080/system/functions -d \n\n{\nservice\n: \nstronghash\n, \nimage\n: \nfunctions/alpine\n, \nenvProcess\n: \nsha512sum\n, \nnetwork\n: \nfunc_functions\n}\n\n\n\n\n\nDelete a function at runtime\n\n\nYou can delete a function through the FaaS-CLI or with the Docker CLI\n\n\n$ docker service rm func_echoit\n\n\n\n\nExploring the functions with \ncurl\n\n\nSample function: Docker Hub Stats (hubstats)\n\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nalexellis2\n\nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d \nlibrary\n\nThe organisation or user library has 128 repositories on the Docker hub.\n\n\n\n\nThe \n-d\n value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.\n\n\nSample function: Node OS Info (nodeinfo)\n\n\nGrab OS, CPU and other info via a Node.js container using the \nos\n module.\n\n\nIf you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.\n\n\nHere is a loop that can be used to invoke the function in a loop to trigger auto-scaling.\n\nwhile [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d \n; done\n\n\n\nExample:\n\n\n# curl -X POST http://localhost:8080/function/func_nodeinfo -d \n\n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839\n\n\n\n\nSample function: webhook stasher (webhookstash)\n\n\nAnother cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.\n\n\n# curl -X POST http://localhost:8080/function/func_webhookstash -d \n{\nevent\n: \nfork\n, \nrepo\n: \nalexellis2/faas\n}\n\nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt\n\n\n\n\n\n\nWhy not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Part 4 - Create a Function"
        }, 
        {
            "location": "/getting-started/testdrive/#openfaas-testdrive", 
            "text": "OpenFaaS (or Functions as a Service) is a framework for building serverless functions on Docker Swarm and Kubernetes with first class metrics. Any UNIX process can be packaged as a function in FaaS enabling you to consume a range of web events without repetitive boiler-plate coding.   Please support the project and put a  Star  on the repo.", 
            "title": "OpenFaaS - TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#begin-the-testdrive", 
            "text": "Begin the TestDrive with Docker Swarm   Here is a screenshot of the API gateway portal - designed for ease of use.", 
            "title": "Begin the TestDrive"
        }, 
        {
            "location": "/getting-started/testdrive/#overview", 
            "text": "We have provided several sample functions which are built-into the  Docker Stack  file we deploy during the test drive. You'll be up and running in a few minutes and invoking functions via the Web UI or  curl . When you're ready to deploy your own function click \"Create Function\" in the UI or head over to the CLI tutorial:   Morning coffee with the OpenFaaS CLI", 
            "title": "Overview"
        }, 
        {
            "location": "/getting-started/testdrive/#pre-reqs", 
            "text": "The guide makes use of a cloud playground service called  play-with-docker.com  that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.  Background info:   There is also a  blog post  that goes into the background of the project.", 
            "title": "Pre-reqs"
        }, 
        {
            "location": "/getting-started/testdrive/#start-here", 
            "text": "So let's head over to  http://play-with-docker.com/  and start a new session. You will probably have to fill out a Captcha.    Click \"Add New Instance\" to create a single Docker host (more can be added later)    This one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:  # docker swarm init --advertise-addr eth0   \\\n  git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  git checkout 0.6.6-beta1   \\\n  ./deploy_stack.sh   \\\n  docker service ls  The shell script makes use of a v3 docker-compose.yml file - read the  deploy_stack.sh  file for more details.   If you are not testing on play-with-docker then remove  --advertise-addr eth0  from first line of the script.     Now that everything's deployed take note of the two ports at the top of the screen:    8080 - the API Gateway and OpenFaaS UI   9090 - the Prometheus metrics endpoint", 
            "title": "Start here"
        }, 
        {
            "location": "/getting-started/testdrive/#install-faas-cli", 
            "text": "We will also install the OpenFaaS CLI which can be used to create, list, invoke and remove functions.  $ curl -sL cli.openfaas.com  |  sh  On your own machine change  | sh  to  | sudo sh , for MacOS you can just use  brew install faas-cli .   Find out what you can do   $ faas-cli --help", 
            "title": "Install FaaS-CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#invoke-the-sample-functions-with-curl-or-postman", 
            "text": "Head over to the  Github and Star the project , or read on to see the input/output from the sample functions.", 
            "title": "Invoke the sample functions with curl or Postman:"
        }, 
        {
            "location": "/getting-started/testdrive/#working-with-the-sample-functions", 
            "text": "You can access the sample functions via the command line with a HTTP POST request, the FaaS-CLI or by using the built-in UI portal.   Invoke the markdown function with the CLI:   $ echo  # Test *Drive* | faas-cli invoke func_markdown h1 Test  em Drive /em /h1    List your functions   $ faas-cli list\nFunction                        Invocations     Replicas\nfunc_echoit                     0               1\nfunc_base64                     0               1\nfunc_decodebase64               0               1\nfunc_markdown                   3               1\nfunc_nodeinfo                   0               1\nfunc_wordcount                  0               1\nfunc_hubstats                   0               1\nfunc_webhookstash               0               1  UI portal:  The UI portal is accessible on:  http://localhost:8080/  - it show a list of functions deployed on your swarm and allows you to test them out.  View screenshot:   You can find out which services are deployed like this:  # docker stack ls\nNAME  SERVICES\nfunc  3\n\n# docker stack ps func\nID            NAME               IMAGE                                  NODE  DESIRED STATE  CURRENT STATE         \nrhzej73haufd  func_gateway.1     alexellis2/faas-gateway:latest         moby  Running        Running 26 minutes ago\nfssz6unq3e74  func_hubstats.1    alexellis2/faas-dockerhubstats:latest  moby  Running        Running 27 minutes ago\nnnlzo6u3pilg  func_prometheus.1  quay.io/prometheus/prometheus:latest   moby  Running        Running 27 minutes ago   Head over to  http://localhost:9090  for your Prometheus metrics   A saved Prometheus view is available here:  metrics overview    Your functions can be accessed via the gateway UI or read on for  curl", 
            "title": "Working with the sample functions"
        }, 
        {
            "location": "/getting-started/testdrive/#build-functions-from-templates-and-the-cli", 
            "text": "The following guides show how to use the CLI and code templates to build functions.  Using a template means you only have to write a handler file in your chosen programming language such as:   Ruby  Node.js  Python  CSharp  Or propose a template for another programming languae   Guides:    Your first serverless Python function with OpenFaaS    Your first serverless .NET / C# function with OpenFaaS", 
            "title": "Build functions from templates and the CLI"
        }, 
        {
            "location": "/getting-started/testdrive/#package-a-custom-docker-image", 
            "text": "Read the developer guide:   Packaging a function   The original blog post also walks through creating a function:   FaaS blog post", 
            "title": "Package a custom Docker image"
        }, 
        {
            "location": "/getting-started/testdrive/#add-new-functions-to-faas-at-runtime", 
            "text": "Option 1: via the FaaS CLI  The FaaS CLI can be used to build functions very quickly though the use of templates. See more details on the FaaS CLI  here .  Option 2: via FaaS UI portal  To attach a function at runtime you can use the \"Create New Function\" button on the portal UI at  http://localhost:8080/     Creating a function via the UI:     Option  Usage      Image  The name of the image you want to use for the function. A good starting point is functions/alpine    Service Name  Describe the name of your service. The Service Name format is: [a-zA-Z_0-9]    fProcess  The process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.    Network  The network  func_functions  is the default network.     Once the create button is clicked, faas will provision a new Docker Swarm service. The newly created function will shortly be available in the list of functions on the left hand side of the UI.  Option 3: Through docker-compose.yml stack file    Edit the docker-compose stack file, then run ./deploy_stack.sh - this will only update changed/added services, not existing ones.  Option 4: Programatically through a HTTP POST to the API Gateway  A HTTP post can also be sent via  curl  etc to the endpoint used by the UI (HTTP post to  /system/functions )  // CreateFunctionRequest create a function in the swarm.\ntype CreateFunctionRequest struct {\n    Service    string `json: service `\n    Image      string `json: image `\n    Network    string `json: network `\n    EnvProcess string `json: envProcess `\n}  Example:  For a quote-of-the-day type of application:  curl localhost:8080/system/functions -d  \n{ service :  oblique ,  image :  vielmetti/faas-oblique ,  envProcess :  /usr/bin/oblique ,  network :  func_functions }   For a hashing algorithm:  curl localhost:8080/system/functions -d  \n{ service :  stronghash ,  image :  functions/alpine ,  envProcess :  sha512sum ,  network :  func_functions }", 
            "title": "Add new functions to FaaS at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#delete-a-function-at-runtime", 
            "text": "You can delete a function through the FaaS-CLI or with the Docker CLI  $ docker service rm func_echoit", 
            "title": "Delete a function at runtime"
        }, 
        {
            "location": "/getting-started/testdrive/#exploring-the-functions-with-curl", 
            "text": "Sample function: Docker Hub Stats (hubstats)  # curl -X POST http://localhost:8080/function/func_hubstats -d  alexellis2 \nThe organisation or user alexellis2 has 99 repositories on the Docker hub.\n\n# curl -X POST http://localhost:8080/function/func_hubstats -d  library \nThe organisation or user library has 128 repositories on the Docker hub.  The  -d  value passes in the argument for your function. This is read via STDIN and used to query the Docker Hub to see how many images you've created/pushed.  Sample function: Node OS Info (nodeinfo)  Grab OS, CPU and other info via a Node.js container using the  os  module.  If you invoke this method in a while loop or with a load-generator tool then it will auto-scale to 5, 10, 15 and finally 20 replicas due to the load. You will then be able to see the various Docker containers responding with a different Hostname for each request as the work is distributed evenly.  Here is a loop that can be used to invoke the function in a loop to trigger auto-scaling. while [ true ] ; do curl -X POST http://localhost:8080/function/func_nodeinfo -d  ; done  Example:  # curl -X POST http://localhost:8080/function/func_nodeinfo -d  \n\nHostname: 9b077a81a489\n\nPlatform: linux\nArch: arm\nCPU count: 1\nUptime: 776839  Sample function: webhook stasher (webhookstash)  Another cool sample function is the Webhook Stasher which saves the body of any data posted to the service to the container's filesystem. Each file is written with the filename of the UNIX time.  # curl -X POST http://localhost:8080/function/func_webhookstash -d  { event :  fork ,  repo :  alexellis2/faas } \nWebhook stashed\n\n# docker ps|grep stash\nd769ca70729d        alexellis2/faas-webhookstash@sha256:b378f1a144202baa8fb008f2c8896f5a8\n\n# docker exec d769ca70729d find .\n.\n./1483999546817280727.txt\n./1483999702130689245.txt\n./1483999702533419188.txt\n./1483999702978454621.txt\n./1483999703284879767.txt\n./1483999719981227578.txt\n./1483999720296180414.txt\n./1483999720666705381.txt\n./1483999720961054638.txt   Why not start the code on play-with-docker.com and then configure a Github repository to send webhooks to the API Gateway?", 
            "title": "Exploring the functions with curl"
        }, 
        {
            "location": "/architecture/", 
            "text": "Architecture\n\n\n\n\nFunction Watchdog\n\n\n\n\nYou can make any Docker image into a serverless function by adding the \nFunction Watchdog\n (a tiny Golang HTTP server)\n\n\nThe \nFunction Watchdog\n is the entrypoint allowing HTTP requests to be forwarded to the target process via STDIN. The response is sent back to the caller by writing to STDOUT from your application.\n\n\n\n\nAPI Gateway / UI Portal\n\n\n\n\nThe API Gateway provides an external route into your functions and collects Cloud Native metrics through Prometheus.\n\n\nYour API Gateway will scale functions according to demand by altering the service replica count in the Docker Swarm or Kubernetes API.\n\n\nA UI is baked in allowing you to invoke functions in your browser and create new ones as needed.\n\n\n\n\n\n\nNote\n\n\nThe API Gateway is a RESTful micro-service and you can view the \nSwagger docs here\n.\n\n\n\n\nPrometheus/Grafana\n\n\nExample of a Grafana dashboard linked to OpenFaaS showing auto-scaling live in action:\n\n\n\n\nSample dashboard JSON file available \nhere\n\n\nCLI\n\n\nAny container or process in a Docker container can be a serverless function in FaaS. Using the \nFaaS CLI\n you can deploy your functions or quickly create new functions from templates such as Node.js or Python.\n\n\n\n\nNote\n\n\nThe CLI is effectively a RESTful client for the API Gateway.\n\n\n\n\nWhen you have OpenFaaS configured you can \nget started with the CLI here\n\n\nFunction examples\n\n\nYou can generate new functions using the FaaS-CLI and built-in templates or use any binary for Windows or Linux in a Docker container.\n\n\nPython\n\n\nhandler.py\n\n\nimport\n \nrequests\n\n\n\ndef\n \nhandle\n(\nreq\n):\n\n        \nr\n \n=\n  \nrequests\n.\nget\n(\nreq\n,\n \ntimeout\n \n=\n \n1\n)\n\n        \nprint\n(\nreq\n \n+\n =\n \n \n+\n \nstr\n(\nr\n.\nstatus_code\n))\n\n\n\n\nNode.js\n\n\nhandler.js\n\n\nuse strict\n\n\n\nmodule\n.\nexports\n \n=\n \n(\ncallback\n,\n \ncontext\n)\n \n=\n \n{\n\n    \ncallback\n(\nnull\n,\n \n{\nmessage\n:\n \nYou said: \n \n+\n \ncontext\n})\n\n\n}\n\n\n\n\nOther languages...\n\n\nSample functions\n in a range of other languages are available in the Github repository.\n\n\nIf there is a language then you would like to see added please contact the project team.", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#architecture", 
            "text": "", 
            "title": "Architecture"
        }, 
        {
            "location": "/architecture/#function-watchdog", 
            "text": "You can make any Docker image into a serverless function by adding the  Function Watchdog  (a tiny Golang HTTP server)  The  Function Watchdog  is the entrypoint allowing HTTP requests to be forwarded to the target process via STDIN. The response is sent back to the caller by writing to STDOUT from your application.", 
            "title": "Function Watchdog"
        }, 
        {
            "location": "/architecture/#api-gateway-ui-portal", 
            "text": "The API Gateway provides an external route into your functions and collects Cloud Native metrics through Prometheus.  Your API Gateway will scale functions according to demand by altering the service replica count in the Docker Swarm or Kubernetes API.  A UI is baked in allowing you to invoke functions in your browser and create new ones as needed.    Note  The API Gateway is a RESTful micro-service and you can view the  Swagger docs here .", 
            "title": "API Gateway / UI Portal"
        }, 
        {
            "location": "/architecture/#prometheusgrafana", 
            "text": "Example of a Grafana dashboard linked to OpenFaaS showing auto-scaling live in action:   Sample dashboard JSON file available  here", 
            "title": "Prometheus/Grafana"
        }, 
        {
            "location": "/architecture/#cli", 
            "text": "Any container or process in a Docker container can be a serverless function in FaaS. Using the  FaaS CLI  you can deploy your functions or quickly create new functions from templates such as Node.js or Python.   Note  The CLI is effectively a RESTful client for the API Gateway.   When you have OpenFaaS configured you can  get started with the CLI here", 
            "title": "CLI"
        }, 
        {
            "location": "/architecture/#function-examples", 
            "text": "You can generate new functions using the FaaS-CLI and built-in templates or use any binary for Windows or Linux in a Docker container.", 
            "title": "Function examples"
        }, 
        {
            "location": "/architecture/#python", 
            "text": "handler.py  import   requests  def   handle ( req ): \n         r   =    requests . get ( req ,   timeout   =   1 ) \n         print ( req   +  =     +   str ( r . status_code ))", 
            "title": "Python"
        }, 
        {
            "location": "/architecture/#nodejs", 
            "text": "handler.js  use strict  module . exports   =   ( callback ,   context )   =   { \n     callback ( null ,   { message :   You said:    +   context })  }", 
            "title": "Node.js"
        }, 
        {
            "location": "/architecture/#other-languages", 
            "text": "Sample functions  in a range of other languages are available in the Github repository.  If there is a language then you would like to see added please contact the project team.", 
            "title": "Other languages..."
        }, 
        {
            "location": "/deployment/swarm/", 
            "text": "Deploy OpenFaaS to Docker Swarm\n\n\n\n\nA Foreword On Security\n\n\nThese instructions are for a development environment. If you plan to expose OpenFaaS on the public Internet you need to enable basic authentication with a proxy such as Kong or Traefik at a minimum.\n\n\nTLS is also highly recomended and freely available from LetsEncrypt.org.\n\n\nRefer to the \nKong\n and \nTraefik\n Integration Guides for instructions on using them with OpenFaaS.\n\n\n\n\nThe deployment guide for Docker Swarm provides a simple one-line command to get you up and running in around 60 seconds.\n\n\nIf you already have a working Docker Swarm you can skip to the \nDeploy OpenFaaS\n section.\n\n\nCreate a Docker Swarm\n\n\nYou can create a single-host Docker Swarm on your laptop with a single command. You don't need any additional software to Docker 17.05 or greater. You can also run these commands on a Linux VM or cloud host running Docker.\n\n\nInitialize Swarm Mode\n\n\n\n\n\n\nInitalise the Swarm master node with:\n\n\n# docker swarm init\n\n\n\n\n\n\nMultiple IP Addresses\n\n\nIf you have more than one IP address you may need to explicitly set the interface the Swarm will advertise on using by adding \n--advertise-addr eth0\n to the command above. Refer to the \nDocker CLI docs\n for more info.\n\n\n\n\n\n\n\n\nTake a note of the join token\n\n\n\n\n\n\nJoin Swarm Workers\n\n\n\n\n\n\nLog into your worker node(s) (if any) and type in the output from \ndocker swarm init\n on the master.\n\n\nIf you've lost this info then type in \ndocker swarm join-token worker\n and then enter that on the worker.\n\n\nIt's also important to pass the \n--advertise-addr\n string to any hosts which have a public IP address.\n\n\n\n\nOptional Firewall Updates\n\n\nCheck whether you need to enable firewall rules for the \nDocker Swarm ports listed here\n.\n\n\n\n\n\n\n\n\nDeploy OpenFaaS\n\n\n\n\n\n\nClone the OpenFaaS repo and checkout the latest stable release:\n\n\n$ git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  git checkout 0.6.7\n\n\n\n\n\n\n\n\nDeploy the OpenFaaS Stack (Linux/OSX)\n    \n$ ./deploy_stack.sh\n\n\n\n\n\n\n\nDeploy the OpenFaaS Stack (Windows Powershell)\n    \n$ ./deploy_stack.ps1\n\n\n\n\n\n\n\n./deploy_stack.*\n scripts can be run at any time and include a set of sample functions.\n\n\n\n\nAsynchronous OpenFaaS\n\n\nThe  provided \n./deploy_extended.sh\n script lets you deploy OpenFaaS with support for Asynchronous functions. Read more about using OpenFaaS with Async support \nhere\n.\n\n\n\n\nConnect to OpenFaaS\n\n\nAPI Gateway\n\n\nOpenFaaS should complete its deployment within a few seconds (or minutes if on a poor WiFi connection), the API gateway and sample functions will be pulled into your local Docker library and you will be able to access the UI at:\n\n\n\n\nhttp://localhost:8080\n\n\n\n\n\n\nLocalhost Times Out\n\n\nIf you're running on Linux you may find that \nlocalhost\n times out when IPv6 is enabled. In this case force an IPv4 address such as \nhttp://127.0.0.1:8080\n.\n\n\n\n\n\n\nPrometheus\n\n\nThe Grafana dashboard linked to OpenFaaS will be accessible at:\n\n\n\n\nhttp://localhost:9090\n\n\n\n\nContinue Getting Started\n\n\nIf you are following the Getting Started Guide you should proceed to \nStep 2 - OpenFaaS UIs\n.", 
            "title": "Docker Swarm"
        }, 
        {
            "location": "/deployment/swarm/#deploy-openfaas-to-docker-swarm", 
            "text": "A Foreword On Security  These instructions are for a development environment. If you plan to expose OpenFaaS on the public Internet you need to enable basic authentication with a proxy such as Kong or Traefik at a minimum.  TLS is also highly recomended and freely available from LetsEncrypt.org.  Refer to the  Kong  and  Traefik  Integration Guides for instructions on using them with OpenFaaS.   The deployment guide for Docker Swarm provides a simple one-line command to get you up and running in around 60 seconds.  If you already have a working Docker Swarm you can skip to the  Deploy OpenFaaS  section.", 
            "title": "Deploy OpenFaaS to Docker Swarm"
        }, 
        {
            "location": "/deployment/swarm/#create-a-docker-swarm", 
            "text": "You can create a single-host Docker Swarm on your laptop with a single command. You don't need any additional software to Docker 17.05 or greater. You can also run these commands on a Linux VM or cloud host running Docker.", 
            "title": "Create a Docker Swarm"
        }, 
        {
            "location": "/deployment/swarm/#initialize-swarm-mode", 
            "text": "Initalise the Swarm master node with:  # docker swarm init   Multiple IP Addresses  If you have more than one IP address you may need to explicitly set the interface the Swarm will advertise on using by adding  --advertise-addr eth0  to the command above. Refer to the  Docker CLI docs  for more info.     Take a note of the join token", 
            "title": "Initialize Swarm Mode"
        }, 
        {
            "location": "/deployment/swarm/#join-swarm-workers", 
            "text": "Log into your worker node(s) (if any) and type in the output from  docker swarm init  on the master.  If you've lost this info then type in  docker swarm join-token worker  and then enter that on the worker.  It's also important to pass the  --advertise-addr  string to any hosts which have a public IP address.   Optional Firewall Updates  Check whether you need to enable firewall rules for the  Docker Swarm ports listed here .", 
            "title": "Join Swarm Workers"
        }, 
        {
            "location": "/deployment/swarm/#deploy-openfaas", 
            "text": "Clone the OpenFaaS repo and checkout the latest stable release:  $ git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  git checkout 0.6.7    Deploy the OpenFaaS Stack (Linux/OSX)\n     $ ./deploy_stack.sh    Deploy the OpenFaaS Stack (Windows Powershell)\n     $ ./deploy_stack.ps1    ./deploy_stack.*  scripts can be run at any time and include a set of sample functions.   Asynchronous OpenFaaS  The  provided  ./deploy_extended.sh  script lets you deploy OpenFaaS with support for Asynchronous functions. Read more about using OpenFaaS with Async support  here .", 
            "title": "Deploy OpenFaaS"
        }, 
        {
            "location": "/deployment/swarm/#connect-to-openfaas", 
            "text": "", 
            "title": "Connect to OpenFaaS"
        }, 
        {
            "location": "/deployment/swarm/#api-gateway", 
            "text": "OpenFaaS should complete its deployment within a few seconds (or minutes if on a poor WiFi connection), the API gateway and sample functions will be pulled into your local Docker library and you will be able to access the UI at:   http://localhost:8080    Localhost Times Out  If you're running on Linux you may find that  localhost  times out when IPv6 is enabled. In this case force an IPv4 address such as  http://127.0.0.1:8080 .", 
            "title": "API Gateway"
        }, 
        {
            "location": "/deployment/swarm/#prometheus", 
            "text": "The Grafana dashboard linked to OpenFaaS will be accessible at:   http://localhost:9090", 
            "title": "Prometheus"
        }, 
        {
            "location": "/deployment/swarm/#continue-getting-started", 
            "text": "If you are following the Getting Started Guide you should proceed to  Step 2 - OpenFaaS UIs .", 
            "title": "Continue Getting Started"
        }, 
        {
            "location": "/deployment/kubernetes/", 
            "text": "Deploy OpenFaaS to Kubernetes\n\n\n\n\nA foreword on security\n\n\nThese instructions are for a development environment. If you plan to expose OpenFaaS on the public Internet you need to enable basic authentication with a proxy such as Kong or Traefik at a minimum.\n\n\nTLS is also highly recomended and freely available from LetsEncrypt.org.\n\n\nRefer to the \nKong\n and \nTraefik\n Integration Guides for instructions on using them with OpenFaaS.\n\n\n\n\nOpenFaaS is Kubernetes-native using \nDeployments\n, \nServices\n and \nSecrets\n. For more detail check out the \n\"faas-netes\" repository\n.\n\n\nIf you already have a working Kubernetes 1.8 cluster you can skip to the \nDeploy OpenFaaS\n section.\n\n\nCreate a Kubernetes Cluster\n\n\nIf you do not already have a Kubernetes cluster follow this guide to deploy one so you can start evaluating OpenFaaS and building functions on your laptop or on a VM (cloud or on-prem).\n\n\n\n\n10 minute guides for minikube / kubeadm\n\n\n\n\nAdditional information on \nsetting up Kubernetes\n.\n\n\nDeploy OpenFaaS\n\n\nTwo alternate methods for deploying OpenFaaS on Kubernetes are provided, using Helm, and manually using \nkubectl\n.\n\n\nIf you are not familiar with Helm you should continue to the \nManual Deployment\n section.\n\n\nHelm Chart\n\n\nA Helm chart is provided \nfaas-netes\n repository. Follow the link below then come back to this guide.\n\n\n\n\nOpenFaaS Helm chart\n\n\n\n\nManual Deployment\n\n\nDeploy either a synchronous or asynchronous OpenFaaS stack, these steps assume you are running \nkubectl\n on a master host.\n\n\n\n\nStandard vs Asynchronous\n\n\nIf you're using OpenFaaS for the first time we recommend deploying the \nsynchronous stack\n.\n\n\n\n\nSynchronous Stack\n\n\nNormal non-async OpenFaaS deployments can be carried out as follows:\n\n\n\n\nClone the \nFaas-Netes\n repository.\n    \n$ git clone https://github.com/openfaas/faas-netes\n\n\n\nDeploy the Synchnronous OpenFaaS stack.\n    \n$ cd faas-netes\n$ kubectl apply -f ./faas.yml,monitoring.yml,rbac.yml\n\n\n\n\n\nAsynchronous Stack\n\n\nAlternatively OpenFaaS can be deployed with support for asynchronous invocation as follows:\n\n\n\n\nAsynchronous Invocation\n\n\nAsynchronous invocation works by queuing requests with \nNATS\n Streaming. See the \nAsynchronous function guide\n for more detail.\n\n\n\n\n\n\nClone the \nFaas-Netes\n repository.\n    \n$ git clone https://github.com/openfaas/faas-netes\n\n\n\nDeploy the OpenFaaS stack with asynchronous invocation support.\n    \n$ cd faas-netes\n$ kubectl apply -f ./faas.async.yml,nats.yml,monitoring.yml,rbac.yml\n\n\n\n\n\nAsynchronous invocation works by queuing requests with NATS Streaming. An alternative implementation is available with Kafka in an \nopen PR\n.\n\n\n\n\nFurther Reading\n\n\nAsynchronous invocation works by queuing requests with \nNATS\n Streaming. See the \nAsynchronous function guide\n for more detail.\n\n\n\n\nConnect to OpenFaaS\n\n\nFor simplicity the default configuration uses NodePorts rather than an IngressController (which is more complicated to setup) to expose access to the OpenFaaS API Gateway and Prometheus.\n\n\n\n\n\n\n\n\nService\n\n\nTCP port\n\n\n\n\n\n\n\n\n\n\nAPI Gateway / UI\n\n\n31112\n\n\n\n\n\n\nPrometheus\n\n\n31119\n\n\n\n\n\n\n\n\n\n\nIngressController (Advanced Users)\n\n\nIf you're an advanced Kubernetes user, you can add an IngressController to your stack and remove the NodePort assignments.\n\n\n\n\nAPI Gateway\n\n\nOpenFaaS should complete its deployment within a few seconds (or minutes if on a poor WiFi connection), the API gateway will be pulled into your local Docker library and you will be able to access the UI at (where \nkubernetes-node-ip\n is the IP address or hostname of your Kubernetes node):\n\n\n\n\nhttp://kubernetes-node-ip:8080\n\n\n\n\n\n\nPrometheus\n\n\nThe Grafana dashboard linked to OpenFaaS will be accessible at:\n\n\n\n\nhttp://kubernetes-node-ip:31119\n\n\n\n\n3.0 Use OpenFaaS\n\n\nAfter deploying OpenFaaS you can start using one of the guides or blog posts to create Serverless functions or test \ncommunity functions\n.\n\n\n\n\nYou can also watch a complete walk-through of OpenFaaS on Kubernetes which demonstrates auto-scaling in action and how to use the Prometheus UI. \nVideo walk-through\n.\n\n\nConnect to the UI\n\n\nDeployed\n\n\nDeploy a function\n\n\nThere are currently no sample functions built into this stack, but we can deploy them quickly via the UI or FaaS-CLI.\n\n\nUsing the CLI\n\n\n\n\nInstall the CLI \n\n\n\n\n$ curl -sL cli.openfaas.com | sudo sh\n\n\n\n\nThen clone some samples to deploy on your cluster.\n\n\n$ git clone https://github.com/openfaas/faas-cli\n\n\n\n\nEdit samples.yml and change your gateway URL from \nlocalhost:8080\n to \nkubernetes-node-ip:31112\n.\n\n\ni.e.\n\n\nprovider\n:\n  \n  \nname\n:\n \nfaas\n\n  \ngateway\n:\n \nhttp://192.168.4.95:31112\n\n\n\n\n\nNow deploy the samples:\n\nLearn about the CLI\n\n\n$ faas-cli deploy -f samples.yml\n\n\n\n\n\n\nThe \nfaas-cli\n also supports an override of \n--gateway http://...\n for example:\n\nBuild your first Python function\n\n\n\n\n$ faas-cli deploy -f samples.yml --gateway http://127.0.0.1:31112\n\n\n\n\nList the functions:\n\n\n$ faas-cli list -f samples.yml\n\nor\n\n$ faas-cli list  --gateway http://127.0.0.1:31112\nFunction                        Invocations     Replicas\ninception                       0               1    \nnodejs-echo                     0               1    \nruby-echo                       0               1    \nshrink-image                    0               1    \nstronghash                      2               1\n\n\n\n\nInvoke a function:\n\n\n$ echo -n Test | faas-cli invoke stronghash --gateway http://127.0.0.1:31112\nc6ee9e33cf5c6715a1d148fd73f7318884b41adcb916021e2bc0e800a5c5dd97f5142178f6ae88c8fdd98e1afb0ce4c8d2c54b5f37b30b7da1997bb33b0b8a31  -\n\n\n\n\n\n\nLearn about the CLI\n\n\n\n\nMorning coffee with the OpenFaaS CLI\n\n\n\n\nBuild your first Python function\n\n\n\n\nYour first serverless Python function with OpenFaaS\n\n\nUse the UI\n\n\n$ git clone https://github.com/openfaas/faas-cli \n \n\\\n\n  faas-cli deploy -f samples.yml\n\n\n\nUsing the UI\n\n\nThe UI is exposed on NodePort 31112.\n\n\nClick \"New Function\" and fill it out with the following:\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nService\n\n\nnodeinfo\n\n\n\n\n\n\nImage\n\n\nfunctions/nodeinfo:latest\n\n\n\n\n\n\nfProcess\n\n\nnode main.js\n\n\n\n\n\n\nNetwork\n\n\ndefault\n\n\n\n\n\n\n\n\nTest the function\n\n\nYour function will appear after a few seconds and you can click \"Invoke\"\n\n\nThe function can also be invoked through the CLI:\n\n\n$ \necho\n -n \n \n|\n faas-cli invoke --gateway http://kubernetes-ip:31112 \n\\\n\n                               --name nodeinfo\n$ \necho\n -n \nverbose\n \n|\n faas-cli invoke --gateway http://kubernetes-ip:31112 \n\\\n\n                                      --name nodeinfo\n\n\n$ echo -n \"\" | faas-cli invoke --gateway http://kubernetes-ip:31112 nodeinfo\n$ echo -n \"verbose\" | faas-cli invoke --gateway http://kubernetes-ip:31112 nodeinfo\n```\n\n\nHelm chart\n\n\nA Helm chart is provided below with experimental support.\n\n\n\n\nOpenFaaS Helm chart", 
            "title": "Kubernetes"
        }, 
        {
            "location": "/deployment/kubernetes/#deploy-openfaas-to-kubernetes", 
            "text": "A foreword on security  These instructions are for a development environment. If you plan to expose OpenFaaS on the public Internet you need to enable basic authentication with a proxy such as Kong or Traefik at a minimum.  TLS is also highly recomended and freely available from LetsEncrypt.org.  Refer to the  Kong  and  Traefik  Integration Guides for instructions on using them with OpenFaaS.   OpenFaaS is Kubernetes-native using  Deployments ,  Services  and  Secrets . For more detail check out the  \"faas-netes\" repository .  If you already have a working Kubernetes 1.8 cluster you can skip to the  Deploy OpenFaaS  section.", 
            "title": "Deploy OpenFaaS to Kubernetes"
        }, 
        {
            "location": "/deployment/kubernetes/#create-a-kubernetes-cluster", 
            "text": "If you do not already have a Kubernetes cluster follow this guide to deploy one so you can start evaluating OpenFaaS and building functions on your laptop or on a VM (cloud or on-prem).   10 minute guides for minikube / kubeadm   Additional information on  setting up Kubernetes .", 
            "title": "Create a Kubernetes Cluster"
        }, 
        {
            "location": "/deployment/kubernetes/#deploy-openfaas", 
            "text": "Two alternate methods for deploying OpenFaaS on Kubernetes are provided, using Helm, and manually using  kubectl .  If you are not familiar with Helm you should continue to the  Manual Deployment  section.", 
            "title": "Deploy OpenFaaS"
        }, 
        {
            "location": "/deployment/kubernetes/#helm-chart", 
            "text": "A Helm chart is provided  faas-netes  repository. Follow the link below then come back to this guide.   OpenFaaS Helm chart", 
            "title": "Helm Chart"
        }, 
        {
            "location": "/deployment/kubernetes/#manual-deployment", 
            "text": "Deploy either a synchronous or asynchronous OpenFaaS stack, these steps assume you are running  kubectl  on a master host.   Standard vs Asynchronous  If you're using OpenFaaS for the first time we recommend deploying the  synchronous stack .", 
            "title": "Manual Deployment"
        }, 
        {
            "location": "/deployment/kubernetes/#synchronous-stack", 
            "text": "Normal non-async OpenFaaS deployments can be carried out as follows:   Clone the  Faas-Netes  repository.\n     $ git clone https://github.com/openfaas/faas-netes  Deploy the Synchnronous OpenFaaS stack.\n     $ cd faas-netes\n$ kubectl apply -f ./faas.yml,monitoring.yml,rbac.yml", 
            "title": "Synchronous Stack"
        }, 
        {
            "location": "/deployment/kubernetes/#asynchronous-stack", 
            "text": "Alternatively OpenFaaS can be deployed with support for asynchronous invocation as follows:   Asynchronous Invocation  Asynchronous invocation works by queuing requests with  NATS  Streaming. See the  Asynchronous function guide  for more detail.    Clone the  Faas-Netes  repository.\n     $ git clone https://github.com/openfaas/faas-netes  Deploy the OpenFaaS stack with asynchronous invocation support.\n     $ cd faas-netes\n$ kubectl apply -f ./faas.async.yml,nats.yml,monitoring.yml,rbac.yml   Asynchronous invocation works by queuing requests with NATS Streaming. An alternative implementation is available with Kafka in an  open PR .   Further Reading  Asynchronous invocation works by queuing requests with  NATS  Streaming. See the  Asynchronous function guide  for more detail.", 
            "title": "Asynchronous Stack"
        }, 
        {
            "location": "/deployment/kubernetes/#connect-to-openfaas", 
            "text": "For simplicity the default configuration uses NodePorts rather than an IngressController (which is more complicated to setup) to expose access to the OpenFaaS API Gateway and Prometheus.     Service  TCP port      API Gateway / UI  31112    Prometheus  31119      IngressController (Advanced Users)  If you're an advanced Kubernetes user, you can add an IngressController to your stack and remove the NodePort assignments.", 
            "title": "Connect to OpenFaaS"
        }, 
        {
            "location": "/deployment/kubernetes/#api-gateway", 
            "text": "OpenFaaS should complete its deployment within a few seconds (or minutes if on a poor WiFi connection), the API gateway will be pulled into your local Docker library and you will be able to access the UI at (where  kubernetes-node-ip  is the IP address or hostname of your Kubernetes node):   http://kubernetes-node-ip:8080", 
            "title": "API Gateway"
        }, 
        {
            "location": "/deployment/kubernetes/#prometheus", 
            "text": "The Grafana dashboard linked to OpenFaaS will be accessible at:   http://kubernetes-node-ip:31119", 
            "title": "Prometheus"
        }, 
        {
            "location": "/deployment/kubernetes/#30-use-openfaas", 
            "text": "After deploying OpenFaaS you can start using one of the guides or blog posts to create Serverless functions or test  community functions .   You can also watch a complete walk-through of OpenFaaS on Kubernetes which demonstrates auto-scaling in action and how to use the Prometheus UI.  Video walk-through .  Connect to the UI", 
            "title": "3.0 Use OpenFaaS"
        }, 
        {
            "location": "/deployment/kubernetes/#deployed", 
            "text": "", 
            "title": "Deployed"
        }, 
        {
            "location": "/deployment/kubernetes/#deploy-a-function", 
            "text": "There are currently no sample functions built into this stack, but we can deploy them quickly via the UI or FaaS-CLI.", 
            "title": "Deploy a function"
        }, 
        {
            "location": "/deployment/kubernetes/#using-the-cli", 
            "text": "Install the CLI    $ curl -sL cli.openfaas.com | sudo sh  Then clone some samples to deploy on your cluster.  $ git clone https://github.com/openfaas/faas-cli  Edit samples.yml and change your gateway URL from  localhost:8080  to  kubernetes-node-ip:31112 .  i.e.  provider :   \n   name :   faas \n   gateway :   http://192.168.4.95:31112   Now deploy the samples: Learn about the CLI  $ faas-cli deploy -f samples.yml   The  faas-cli  also supports an override of  --gateway http://...  for example: Build your first Python function   $ faas-cli deploy -f samples.yml --gateway http://127.0.0.1:31112  List the functions:  $ faas-cli list -f samples.yml\n\nor\n\n$ faas-cli list  --gateway http://127.0.0.1:31112\nFunction                        Invocations     Replicas\ninception                       0               1    \nnodejs-echo                     0               1    \nruby-echo                       0               1    \nshrink-image                    0               1    \nstronghash                      2               1  Invoke a function:  $ echo -n Test | faas-cli invoke stronghash --gateway http://127.0.0.1:31112\nc6ee9e33cf5c6715a1d148fd73f7318884b41adcb916021e2bc0e800a5c5dd97f5142178f6ae88c8fdd98e1afb0ce4c8d2c54b5f37b30b7da1997bb33b0b8a31  -   Learn about the CLI   Morning coffee with the OpenFaaS CLI   Build your first Python function   Your first serverless Python function with OpenFaaS  Use the UI  $ git clone https://github.com/openfaas/faas-cli    \\ \n  faas-cli deploy -f samples.yml", 
            "title": "Using the CLI"
        }, 
        {
            "location": "/deployment/kubernetes/#using-the-ui", 
            "text": "The UI is exposed on NodePort 31112.  Click \"New Function\" and fill it out with the following:     Field  Value      Service  nodeinfo    Image  functions/nodeinfo:latest    fProcess  node main.js    Network  default", 
            "title": "Using the UI"
        }, 
        {
            "location": "/deployment/kubernetes/#test-the-function", 
            "text": "Your function will appear after a few seconds and you can click \"Invoke\"  The function can also be invoked through the CLI:  $  echo  -n    |  faas-cli invoke --gateway http://kubernetes-ip:31112  \\ \n                               --name nodeinfo\n$  echo  -n  verbose   |  faas-cli invoke --gateway http://kubernetes-ip:31112  \\ \n                                      --name nodeinfo \n$ echo -n \"\" | faas-cli invoke --gateway http://kubernetes-ip:31112 nodeinfo\n$ echo -n \"verbose\" | faas-cli invoke --gateway http://kubernetes-ip:31112 nodeinfo\n```", 
            "title": "Test the function"
        }, 
        {
            "location": "/deployment/kubernetes/#helm-chart_1", 
            "text": "A Helm chart is provided below with experimental support.   OpenFaaS Helm chart", 
            "title": "Helm chart"
        }, 
        {
            "location": "/deployment/play-with-docker/", 
            "text": "Deployment guide for Play-with-Docker\n\n\nOne-click Deployment\n\n\nYou can quickly start OpenFaaS on Docker Swarm online using the community-run Docker playground: play-with-docker.com (PWD) by clicking the button below:\n\n\n\n\nManual Deployment\n\n\nThe guide makes use of a cloud playground service called \nplay-with-docker.com\n that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.\n\n\n\n\n\n\nGo to \nhttp://play-with-docker.com/\n and start a new session. You will probably have to fill out a Captcha.\n\n\n\n\n\n\nClick \"Add New Instance\" to create a single Docker host (more can be added later)\n\n\n\n\n\n\nThis one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:\n\n\n# docker swarm init --advertise-addr eth0 \n \\\n  git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  git checkout 0.6.7 \n \\\n  ./deploy_stack.sh \n \\\n  docker service ls\n\n\n\n\nThe shell script makes use of a v3 docker-compose.yml file - read the \ndeploy_stack.sh\n file for more details.\n\n\n\n\n\n\nNow that everything's deployed take note of the two ports at the top of the screen:\n\n\n\n\n\n\n8080 - the API Gateway and OpenFaaS UI\n\n\n\n\n9090 - the Prometheus metrics endpoint", 
            "title": "Play-with-Docker"
        }, 
        {
            "location": "/deployment/play-with-docker/#deployment-guide-for-play-with-docker", 
            "text": "", 
            "title": "Deployment guide for Play-with-Docker"
        }, 
        {
            "location": "/deployment/play-with-docker/#one-click-deployment", 
            "text": "You can quickly start OpenFaaS on Docker Swarm online using the community-run Docker playground: play-with-docker.com (PWD) by clicking the button below:", 
            "title": "One-click Deployment"
        }, 
        {
            "location": "/deployment/play-with-docker/#manual-deployment", 
            "text": "The guide makes use of a cloud playground service called  play-with-docker.com  that provides free Docker hosts for around 5 hours. If you want to try this on your own laptop just follow along.    Go to  http://play-with-docker.com/  and start a new session. You will probably have to fill out a Captcha.    Click \"Add New Instance\" to create a single Docker host (more can be added later)    This one-shot script clones the code, sets up a Docker Swarm master node then deploys OpenFaaS with the sample stack:  # docker swarm init --advertise-addr eth0   \\\n  git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  git checkout 0.6.7   \\\n  ./deploy_stack.sh   \\\n  docker service ls  The shell script makes use of a v3 docker-compose.yml file - read the  deploy_stack.sh  file for more details.    Now that everything's deployed take note of the two ports at the top of the screen:    8080 - the API Gateway and OpenFaaS UI   9090 - the Prometheus metrics endpoint", 
            "title": "Manual Deployment"
        }, 
        {
            "location": "/integrations/kong/", 
            "text": "Integrate Kong with your OpenFaaS cluster\n\n\nKong\n is an API gateway that provides features such as security, logging, and rate limiting. By putting this in front of OpenFaaS you can quickly get access to these things and a lot more via \nthe many other plugins written\n for it.\n\n\nBelow is a demo of how you could use Kong as an authentication layer for OpenFaaS.\n\n\nSetup OpenFaaS\n\n\nIf you haven't already setup OpenFaaS then you can follow one of the deployment guides available here:\n\n\n\n\nDocker Swarm\n\n\nKubernetes\n\n\n\n\nHere is a quick reference for Docker Swarm:\n\n\n$ docker swarm init --advertise-addr $(hostname -i)\n\n$ git clone https://github.com/openfaas/faas \n \\\n  cd faas \n \\\n  ./deploy_stack.sh\n\n\n\n\nCheck that one of the sample functions works\n\n\n$ curl localhost:8080/function/func_echoit -d \nhello world\n\nhello world\n\n\n\n\nSetup Kong\n\n\nKong stores its configuration in Postgres, so we'll create a Postgres and Kong service then run a one-off migration too.\n\n\nDeploy Postgres and optionally set the \nPOSTGRES_PASSWORD\n\n\n$ docker service create --name kong-database \\\n    --network func_functions --detach=false \\\n    --constraint \nnode.role == manager\n \\\n    -e \nPOSTGRES_USER=kong\n \\\n    -e \nPOSTGRES_DB=kong\n \\\n    -e \nPOSTGRES_PASSWORD=secretpassword\n \\\n    postgres:9.4\n\n\n\n\nNow we will use the Kong image to populate default configuration in the Postgres database:\n\n\n$ docker service create --name=kong-migrations \\\n    --network func_functions --detach=false --restart-condition=none \\\n    -e \nKONG_DATABASE=postgres\n \\\n    -e \nKONG_PG_HOST=kong-database\n \\\n    -e \nKONG_PG_PASSWORD=secretpassword\n \\\n    kong:latest kong migrations up\n\n\n\n\nThe last service is Kong itself:\n\n\n$ docker service create --name kong \\\n    --network func_functions --detach=false \\\n    --constraint \nnode.role == manager\n \\\n    -e \nKONG_DATABASE=postgres\n \\\n    -e \nKONG_PG_HOST=kong-database\n \\\n    -e \nKONG_PG_PASSWORD=secretpassword\n \\\n    -e \nKONG_PROXY_ACCESS_LOG=/dev/stdout\n \\\n    -e \nKONG_ADMIN_ACCESS_LOG=/dev/stdout\n \\\n    -e \nKONG_PROXY_ERROR_LOG=/dev/stderr\n \\\n    -e \nKONG_ADMIN_ERROR_LOG=/dev/stderr\n \\\n    -p 8000:8000 \\\n    -p 8443:8443 \\\n    kong:latest\n\n\n\n\nDoing things the right way\n\n\nKong has an admin port with you can expose by adding \n-p 8001:8001\n. In this guide we will hide the port from the off-set so that if you do not have a firewall configured yet, there is less risk of someone gaining access.\n\n\nCreate a \ncurl\n command alias so we can talk to the Kong admin without exposing its ports to the network.\n\n\n$ alias kong_admin_curl=\ndocker exec $(docker ps -q -f name=\nkong\\.\n) curl\n\n\n\nSee that Kong admin is up and running\n\n$ kong_admin_curl -i localhost:8001\nHTTP/1.1 200\n...\n\n\n\nUse Kong to secure OpenFaaS\n\n\nProxy OpenFaaS's functions through Kong\n\n$ kong_admin_curl -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data \nname=function\n \\\n    --data \nuris=/function\n \\\n    --data \nupstream_url=http://gateway:8080/function\n\n\n$ curl localhost:8000/function/func_echoit -d \nhello world\n\nhello world\n\n\n\nRequire basic authentication\n\n\nEnable the basic-auth plugin in Kong\n\n\n$ kong_admin_curl -X POST http://localhost:8001/plugins \\\n    --data \nname=basic-auth\n \\\n    --data \nconfig.hide_credentials=true\n\n\n\n\n\nCreate a consumer with credentials\n\n\n$ kong_admin_curl -d \nusername=aladdin\n http://localhost:8001/consumers/\n\n$ kong_admin_curl -X POST http://localhost:8001/consumers/aladdin/basic-auth \\\n    --data \nusername=aladdin\n \\\n    --data \npassword=OpenSesame\n\n\n\n\n\nVerify that authentication works\n\n\n$ curl localhost:8000/function/func_echoit -d \nhello world\n\n{\nmessage\n:\nUnauthorized\n}\n\n$ curl localhost:8000/function/func_echoit -d \nhello world\n \\\n    -H \nAuthorization: Basic xxxxxx\n\n{\nmessage\n:\nInvalid authentication credentials\n}\n\n$ echo -n aladdin:OpenSesame | base64\nYWxhZGRpbjpPcGVuU2VzYW1l\n\n$ curl localhost:8000/function/func_echoit -d \nhello world\n \\\n    -H \nAuthorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l\n\nhello world\n\n\n\n\nNow lets expose the /ui directory so we can securely use the web GUI\n\n\n$ kong_admin_curl -i -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data \nname=ui\n \\\n    --data \nuris=/ui\n \\\n    --data \nupstream_url=http://gateway:8080/ui\n\n\n\n\n\nAdditionally we need to expose /system/functions since the UI makes Ajax requests to it\n\n\n$ kong_admin_curl -i -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data \nname=system-functions\n \\\n    --data \nuris=/system/functions\n \\\n    --data \nupstream_url=http://gateway:8080/system/functions\n\n\n\n\n\nVerify that the UI is secure\n\n\n$ curl -i localhost:8000/ui/ \\\n    -H \nAuthorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l\n\n\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\n...\n\n\n\n\nNow visit \nhttp://localhost:8000/ui/\n in your browser where you will be asked for credentials.\n\n\nAdd SSL\n\n\nBasic authentication does not protect from man in the middle attacks, so lets add SSL to encrypt the communication.\n\n\nCreate a cert. Here in the demo, we are creating selfsigned certs, but in production you should skip this step and use your existing certificates (or get some from Lets Encrypt).\n\n$ openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n  -keyout /tmp/selfsigned.key -out /tmp/selfsigned.pem \\\n  -subj \n/C=US/ST=CA/L=L/O=OrgName/OU=IT Department/CN=example.com\n\n\n\n\nAdd cert to Kong\n\n\n$ kong_admin_curl -X POST http://localhost:8001/certificates \\\n    -F \ncert=$(cat /tmp/selfsigned.pem)\n \\\n    -F \nkey=$(cat /tmp/selfsigned.key)\n \\\n    -F \nsnis=example.com\n\n\nHTTP/1.1 201 Created\n...\n\n\n\n\nPut the cert in front OpenFaaS\n\n\n$ kong_admin_curl -i -X POST http://localhost:8001/apis \\\n    -d \nname=ssl-api\n \\\n    -d \nupstream_url=http://gateway:8080\n \\\n    -d \nhosts=example.com\n\nHTTP/1.1 201 Created\n...\n\n\n\n\nVerify that the cert is now in use. Note the '-k' parameter is just here to work around the fact that we are using self signed certs.\n\n$ curl -k https://localhost:8443/function/func_echoit \\\n  -d \nhello world\n -H \nHost: example.com \n\\\n  -H \nAuthorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l\n\nhello world\n\n\n\nConfigure your firewall\n\n\nBetween OpenFaaS and Kong a lot of ports are exposed on your host machine. Most importantly you should hide port 8080 since that is where OpenFaaS's functions live which you were trying to secure in the first place. In the end it is best to only expose either 8000 or 8443 out of your network depending if you added SSL or not.\n\n\nAnother option concerning port 8000 is to expose both 8000 and 8443 and enable \nhttps_only\n which is used to notify clients to upgrade to https from http.", 
            "title": "Kong"
        }, 
        {
            "location": "/integrations/kong/#integrate-kong-with-your-openfaas-cluster", 
            "text": "Kong  is an API gateway that provides features such as security, logging, and rate limiting. By putting this in front of OpenFaaS you can quickly get access to these things and a lot more via  the many other plugins written  for it.  Below is a demo of how you could use Kong as an authentication layer for OpenFaaS.", 
            "title": "Integrate Kong with your OpenFaaS cluster"
        }, 
        {
            "location": "/integrations/kong/#setup-openfaas", 
            "text": "If you haven't already setup OpenFaaS then you can follow one of the deployment guides available here:   Docker Swarm  Kubernetes   Here is a quick reference for Docker Swarm:  $ docker swarm init --advertise-addr $(hostname -i)\n\n$ git clone https://github.com/openfaas/faas   \\\n  cd faas   \\\n  ./deploy_stack.sh  Check that one of the sample functions works  $ curl localhost:8080/function/func_echoit -d  hello world \nhello world", 
            "title": "Setup OpenFaaS"
        }, 
        {
            "location": "/integrations/kong/#setup-kong", 
            "text": "Kong stores its configuration in Postgres, so we'll create a Postgres and Kong service then run a one-off migration too.  Deploy Postgres and optionally set the  POSTGRES_PASSWORD  $ docker service create --name kong-database \\\n    --network func_functions --detach=false \\\n    --constraint  node.role == manager  \\\n    -e  POSTGRES_USER=kong  \\\n    -e  POSTGRES_DB=kong  \\\n    -e  POSTGRES_PASSWORD=secretpassword  \\\n    postgres:9.4  Now we will use the Kong image to populate default configuration in the Postgres database:  $ docker service create --name=kong-migrations \\\n    --network func_functions --detach=false --restart-condition=none \\\n    -e  KONG_DATABASE=postgres  \\\n    -e  KONG_PG_HOST=kong-database  \\\n    -e  KONG_PG_PASSWORD=secretpassword  \\\n    kong:latest kong migrations up  The last service is Kong itself:  $ docker service create --name kong \\\n    --network func_functions --detach=false \\\n    --constraint  node.role == manager  \\\n    -e  KONG_DATABASE=postgres  \\\n    -e  KONG_PG_HOST=kong-database  \\\n    -e  KONG_PG_PASSWORD=secretpassword  \\\n    -e  KONG_PROXY_ACCESS_LOG=/dev/stdout  \\\n    -e  KONG_ADMIN_ACCESS_LOG=/dev/stdout  \\\n    -e  KONG_PROXY_ERROR_LOG=/dev/stderr  \\\n    -e  KONG_ADMIN_ERROR_LOG=/dev/stderr  \\\n    -p 8000:8000 \\\n    -p 8443:8443 \\\n    kong:latest  Doing things the right way  Kong has an admin port with you can expose by adding  -p 8001:8001 . In this guide we will hide the port from the off-set so that if you do not have a firewall configured yet, there is less risk of someone gaining access.  Create a  curl  command alias so we can talk to the Kong admin without exposing its ports to the network.  $ alias kong_admin_curl= docker exec $(docker ps -q -f name= kong\\. ) curl  \nSee that Kong admin is up and running $ kong_admin_curl -i localhost:8001\nHTTP/1.1 200\n...", 
            "title": "Setup Kong"
        }, 
        {
            "location": "/integrations/kong/#use-kong-to-secure-openfaas", 
            "text": "Proxy OpenFaaS's functions through Kong $ kong_admin_curl -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data  name=function  \\\n    --data  uris=/function  \\\n    --data  upstream_url=http://gateway:8080/function \n\n$ curl localhost:8000/function/func_echoit -d  hello world \nhello world", 
            "title": "Use Kong to secure OpenFaaS"
        }, 
        {
            "location": "/integrations/kong/#require-basic-authentication", 
            "text": "Enable the basic-auth plugin in Kong  $ kong_admin_curl -X POST http://localhost:8001/plugins \\\n    --data  name=basic-auth  \\\n    --data  config.hide_credentials=true   Create a consumer with credentials  $ kong_admin_curl -d  username=aladdin  http://localhost:8001/consumers/\n\n$ kong_admin_curl -X POST http://localhost:8001/consumers/aladdin/basic-auth \\\n    --data  username=aladdin  \\\n    --data  password=OpenSesame   Verify that authentication works  $ curl localhost:8000/function/func_echoit -d  hello world \n{ message : Unauthorized }\n\n$ curl localhost:8000/function/func_echoit -d  hello world  \\\n    -H  Authorization: Basic xxxxxx \n{ message : Invalid authentication credentials }\n\n$ echo -n aladdin:OpenSesame | base64\nYWxhZGRpbjpPcGVuU2VzYW1l\n\n$ curl localhost:8000/function/func_echoit -d  hello world  \\\n    -H  Authorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l \nhello world  Now lets expose the /ui directory so we can securely use the web GUI  $ kong_admin_curl -i -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data  name=ui  \\\n    --data  uris=/ui  \\\n    --data  upstream_url=http://gateway:8080/ui   Additionally we need to expose /system/functions since the UI makes Ajax requests to it  $ kong_admin_curl -i -X POST \\\n    --url http://localhost:8001/apis/ \\\n    --data  name=system-functions  \\\n    --data  uris=/system/functions  \\\n    --data  upstream_url=http://gateway:8080/system/functions   Verify that the UI is secure  $ curl -i localhost:8000/ui/ \\\n    -H  Authorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l \n\nHTTP/1.1 200 OK\nContent-Type: text/html; charset=utf-8\n...  Now visit  http://localhost:8000/ui/  in your browser where you will be asked for credentials.", 
            "title": "Require basic authentication"
        }, 
        {
            "location": "/integrations/kong/#add-ssl", 
            "text": "Basic authentication does not protect from man in the middle attacks, so lets add SSL to encrypt the communication.  Create a cert. Here in the demo, we are creating selfsigned certs, but in production you should skip this step and use your existing certificates (or get some from Lets Encrypt). $ openssl req -x509 -nodes -days 365 -newkey rsa:2048 \\\n  -keyout /tmp/selfsigned.key -out /tmp/selfsigned.pem \\\n  -subj  /C=US/ST=CA/L=L/O=OrgName/OU=IT Department/CN=example.com   Add cert to Kong  $ kong_admin_curl -X POST http://localhost:8001/certificates \\\n    -F  cert=$(cat /tmp/selfsigned.pem)  \\\n    -F  key=$(cat /tmp/selfsigned.key)  \\\n    -F  snis=example.com \n\nHTTP/1.1 201 Created\n...  Put the cert in front OpenFaaS  $ kong_admin_curl -i -X POST http://localhost:8001/apis \\\n    -d  name=ssl-api  \\\n    -d  upstream_url=http://gateway:8080  \\\n    -d  hosts=example.com \nHTTP/1.1 201 Created\n...  Verify that the cert is now in use. Note the '-k' parameter is just here to work around the fact that we are using self signed certs. $ curl -k https://localhost:8443/function/func_echoit \\\n  -d  hello world  -H  Host: example.com  \\\n  -H  Authorization: Basic YWxhZGRpbjpPcGVuU2VzYW1l \nhello world", 
            "title": "Add SSL"
        }, 
        {
            "location": "/integrations/kong/#configure-your-firewall", 
            "text": "Between OpenFaaS and Kong a lot of ports are exposed on your host machine. Most importantly you should hide port 8080 since that is where OpenFaaS's functions live which you were trying to secure in the first place. In the end it is best to only expose either 8000 or 8443 out of your network depending if you added SSL or not.  Another option concerning port 8000 is to expose both 8000 and 8443 and enable  https_only  which is used to notify clients to upgrade to https from http.", 
            "title": "Configure your firewall"
        }, 
        {
            "location": "/integrations/traefik/", 
            "text": "Integrate Traefik with your OpenFaaS cluster\n\n\n\n\nTr\u00e6fik (pronounced like traffic) is a modern HTTP reverse proxy and\nload balancer made to deploy microservices with ease.\n- traefik.io\n\n\n\n\nIn addition, \nTraefik\n offers Basic Authentication and easy SSL setup, using LetsEncrypt. It\nsupports several backends, such as Docker Swarm and Kubernetes.\n\n\nSetup OpenFaaS\n\n\nOpenFaaS setup and configuration instructions can be found here:\n\n\n\n\nDocker Swarm\n\n\nKubernetes\n\n\n\n\nTo quickly setup with Docker Swarm:\n\n$ docker swarm init --advertise-addr $(hostname -i)\n\n$ git clone https://github.com/alexellis/faas\n$ cd faas\n$ ./deploy_stack.sh\n\n\n\nConfigure Traefik for Basic Authentication\n\n\nGenerate an MD5 hashed password\n\n\nUse htpasswd to generate a hashed password\n\n$  htpasswd -c ./password.txt user\n\n\nAdd a new password when prompted. The new credentials can be found in\nthe \npassword.txt\n file.\n\n\nAdd Traefik configuration to docker-compose.yml\n\n\nAdd an entry under \nservices\n with the Traefik configuration\n\n# docker-compose.yml\nversion: \n3.2\n\nservices:\n    traefik:\n        image: traefik:v1.3\n        command: -c --docker=true\n            --docker.swarmmode=true\n            --docker.domain=traefik\n            --docker.watch=true\n            --web=true\n            --debug=true\n            --defaultEntryPoints=\nhttp\n\n            --entryPoints=\nName:http Address::80\n\n        ports:\n            - 80:80\n            - 8080:8080\n        volumes:\n            - \n/var/run/docker.sock:/var/run/docker.sock\n\n        networks:\n            - functions\n        deploy:\n            placement:\n                constraints: [node.role == manager]\n\n\n\nUpdate the Gateway service\n\n\nTraefik requires some service labels to discover the gateway service.\nUpdate the gateway configuration to remove the port property and add\nthe appropriate labels.\n\n# docker-compose.yml\n...\n    gateway:\n        ...\n        # ports:\n        #     - 8080:8080\n        ...\n        deploy:\n            labels:\n                - traefik.port=8080\n                - traefik.frontend.rule=PathPrefix:/ui,/system,/function\n                - traefik.frontend.auth.basic=user:$$apr1$$MU....4XHRJ3. #copy/paste the contents of password.txt here\n...\n\n\nRather than publicly exposing port 8080, the added \ntraefik.port\n label will\nmake the gateway service available to Traefik on port 8080, but not\npublicly. Requests will now pass through Traefik and be forwarded on. The\n\nPathPrefix\n property adds the ability to add different routes to\ndifferent services. Adding \n/ui,/system,/function\n allows for routing to all the\nGateway endpoints. The \nbasic.auth\n label should\ninclude the username and the hashed password. Remember to escape any special\ncharacters, so if the password contains a \n$\n, you can escape it by\ndoubling up \n$$\n just like the above.\n\n\nRe-Deploy OpenFaaS\n\n\nRedeploy OpenFaaS to update the service with the new changes.\n\n$ ./deploy_stack.yml\n\n\n\nTest\n\n\n$ curl -u user:password -X POST http://localhost/function/func_echoit -d \nhello OpenFaaS\n\nhello OpenFaaS\n$curl -X POST http://localhost/function/func_echoit -d \nhello OpenFaaS\n\n401 Unauthorized\n\n\nVisit the browser UI at \nhttp://localhost/ui/\n. You should\nbe greeted with a login alert.\n\n\nConfigure Traefik with SSL Support\n\n\nUpdate Traefik configuration\n\n\nTraefik makes it extremely easy to add SSL support using\nLetsEncrypt. Add \n443\n to the list of ports in the \ntraefik\n\nservice, add the following flags to the command property\nof the \ntraefik\n service in the \ndocker-compose.yml\n file,\nand add a new \nacme\n volume under the \nvolumes\n property.\n\n# docker-compose.yml\nversion: \n3.2\n\nservices:\n    traefik:\n        command: -c --docker=true\n            --docker.swarmmode=true\n            --docker.domain=traefik\n            --docker.watch=true\n            --web=true\n            --debug=true\n            --defaultEntryPoints=\nhttp,https\n\n            --acme=true\n            --acme.domains=\nyour-domain.com, \nwww.your-domain-com\n\n            --acme.email=your-email@email.com\n            --acme.ondemand=true\n            --acme.onhostrule=true\n            --acme.storage=/etc/traefik/acme/acme.json\n            --entryPoints=\nName:https Address::443 TLS\n\n            --entryPoints=\nName:http Address::80\n\n        ports:\n            - 80:80\n            - 8080:8080\n            - 443:443\n        volumes:\n            - \n/var/run/docker.sock:/var/run/docker.sock\n            - \nacme:/etc/traefik/acme\n\n...\n\n\n\nAt the bottom of the \ndocker-compose.yml\n file, add a new\nnamed volume.\n\nvolumes:\n    acme:\n# end of file\n\n\n\nRe-Deploy the OpenFaaS service\n\n\n$ ./deploy_stack.sh\n\n\n\n\nTest\n\n\n$ curl -u user:password -X POST https://your-domain.com/function/func_echoit -d \nhello OpenFaaS\n\nhello OpenFaaS\n$curl -X POST https://your-domain.com/function/func_echoit -d \nhello OpenFaaS\n\n401 Unauthorized\n\n\n\n\nVisit the browser UI at \nhttps://your-domain.com/ui/\n. You should\nbe greeted with a login alert.", 
            "title": "Traefik"
        }, 
        {
            "location": "/integrations/traefik/#integrate-traefik-with-your-openfaas-cluster", 
            "text": "Tr\u00e6fik (pronounced like traffic) is a modern HTTP reverse proxy and\nload balancer made to deploy microservices with ease.\n- traefik.io   In addition,  Traefik  offers Basic Authentication and easy SSL setup, using LetsEncrypt. It\nsupports several backends, such as Docker Swarm and Kubernetes.", 
            "title": "Integrate Traefik with your OpenFaaS cluster"
        }, 
        {
            "location": "/integrations/traefik/#setup-openfaas", 
            "text": "OpenFaaS setup and configuration instructions can be found here:   Docker Swarm  Kubernetes   To quickly setup with Docker Swarm: $ docker swarm init --advertise-addr $(hostname -i)\n\n$ git clone https://github.com/alexellis/faas\n$ cd faas\n$ ./deploy_stack.sh", 
            "title": "Setup OpenFaaS"
        }, 
        {
            "location": "/integrations/traefik/#configure-traefik-for-basic-authentication", 
            "text": "", 
            "title": "Configure Traefik for Basic Authentication"
        }, 
        {
            "location": "/integrations/traefik/#generate-an-md5-hashed-password", 
            "text": "Use htpasswd to generate a hashed password $  htpasswd -c ./password.txt user \nAdd a new password when prompted. The new credentials can be found in\nthe  password.txt  file.", 
            "title": "Generate an MD5 hashed password"
        }, 
        {
            "location": "/integrations/traefik/#add-traefik-configuration-to-docker-composeyml", 
            "text": "Add an entry under  services  with the Traefik configuration # docker-compose.yml\nversion:  3.2 \nservices:\n    traefik:\n        image: traefik:v1.3\n        command: -c --docker=true\n            --docker.swarmmode=true\n            --docker.domain=traefik\n            --docker.watch=true\n            --web=true\n            --debug=true\n            --defaultEntryPoints= http \n            --entryPoints= Name:http Address::80 \n        ports:\n            - 80:80\n            - 8080:8080\n        volumes:\n            -  /var/run/docker.sock:/var/run/docker.sock \n        networks:\n            - functions\n        deploy:\n            placement:\n                constraints: [node.role == manager]", 
            "title": "Add Traefik configuration to docker-compose.yml"
        }, 
        {
            "location": "/integrations/traefik/#update-the-gateway-service", 
            "text": "Traefik requires some service labels to discover the gateway service.\nUpdate the gateway configuration to remove the port property and add\nthe appropriate labels. # docker-compose.yml\n...\n    gateway:\n        ...\n        # ports:\n        #     - 8080:8080\n        ...\n        deploy:\n            labels:\n                - traefik.port=8080\n                - traefik.frontend.rule=PathPrefix:/ui,/system,/function\n                - traefik.frontend.auth.basic=user:$$apr1$$MU....4XHRJ3. #copy/paste the contents of password.txt here\n... \nRather than publicly exposing port 8080, the added  traefik.port  label will\nmake the gateway service available to Traefik on port 8080, but not\npublicly. Requests will now pass through Traefik and be forwarded on. The PathPrefix  property adds the ability to add different routes to\ndifferent services. Adding  /ui,/system,/function  allows for routing to all the\nGateway endpoints. The  basic.auth  label should\ninclude the username and the hashed password. Remember to escape any special\ncharacters, so if the password contains a  $ , you can escape it by\ndoubling up  $$  just like the above.", 
            "title": "Update the Gateway service"
        }, 
        {
            "location": "/integrations/traefik/#re-deploy-openfaas", 
            "text": "Redeploy OpenFaaS to update the service with the new changes. $ ./deploy_stack.yml", 
            "title": "Re-Deploy OpenFaaS"
        }, 
        {
            "location": "/integrations/traefik/#test", 
            "text": "$ curl -u user:password -X POST http://localhost/function/func_echoit -d  hello OpenFaaS \nhello OpenFaaS\n$curl -X POST http://localhost/function/func_echoit -d  hello OpenFaaS \n401 Unauthorized \nVisit the browser UI at  http://localhost/ui/ . You should\nbe greeted with a login alert.", 
            "title": "Test"
        }, 
        {
            "location": "/integrations/traefik/#configure-traefik-with-ssl-support", 
            "text": "", 
            "title": "Configure Traefik with SSL Support"
        }, 
        {
            "location": "/integrations/traefik/#update-traefik-configuration", 
            "text": "Traefik makes it extremely easy to add SSL support using\nLetsEncrypt. Add  443  to the list of ports in the  traefik \nservice, add the following flags to the command property\nof the  traefik  service in the  docker-compose.yml  file,\nand add a new  acme  volume under the  volumes  property. # docker-compose.yml\nversion:  3.2 \nservices:\n    traefik:\n        command: -c --docker=true\n            --docker.swarmmode=true\n            --docker.domain=traefik\n            --docker.watch=true\n            --web=true\n            --debug=true\n            --defaultEntryPoints= http,https \n            --acme=true\n            --acme.domains= your-domain.com,  www.your-domain-com \n            --acme.email=your-email@email.com\n            --acme.ondemand=true\n            --acme.onhostrule=true\n            --acme.storage=/etc/traefik/acme/acme.json\n            --entryPoints= Name:https Address::443 TLS \n            --entryPoints= Name:http Address::80 \n        ports:\n            - 80:80\n            - 8080:8080\n            - 443:443\n        volumes:\n            -  /var/run/docker.sock:/var/run/docker.sock\n            -  acme:/etc/traefik/acme \n...  At the bottom of the  docker-compose.yml  file, add a new\nnamed volume. volumes:\n    acme:\n# end of file", 
            "title": "Update Traefik configuration"
        }, 
        {
            "location": "/integrations/traefik/#re-deploy-the-openfaas-service", 
            "text": "$ ./deploy_stack.sh", 
            "title": "Re-Deploy the OpenFaaS service"
        }, 
        {
            "location": "/integrations/traefik/#test_1", 
            "text": "$ curl -u user:password -X POST https://your-domain.com/function/func_echoit -d  hello OpenFaaS \nhello OpenFaaS\n$curl -X POST https://your-domain.com/function/func_echoit -d  hello OpenFaaS \n401 Unauthorized  Visit the browser UI at  https://your-domain.com/ui/ . You should\nbe greeted with a login alert.", 
            "title": "Test"
        }, 
        {
            "location": "/developer/gateway/", 
            "text": "API Gateway\n\n\nTo work on the OpenFaaS API Gateway component checkout the \"./build.sh\" scripts and acompanying Dockerfiles.\n\n\n\n\nRoadmap and Contributing\n\n\n\n\nBuild a development API Gateway\n\n\n\n\nBuild a new development Docker image:\n\n\n\n\n$ cd gateway/\n$ ./build.sh\n\n\n\n\nThis creates a Docker image with the name \nfunctions/gateway:latest-dev\n, but if you want to use something else then pass the tag as an argument to the \n./build.sh\n script. I.e. \n./build.sh labels-pr\n.\n\n\n\n\n\n\nNow edit the Docker image for the \ngateway\n service in your \ndocker-compose.yml\n file.\n\n\n\n\n\n\nRedeploy the stack.\n\n\n\n\n\n\nTest. Repeat.\n\n\nWork on the UI the quick way\n\n\nWorking on the UI with the procedure above could take up to a minute to iterate between changing code and testing the changes. This section of the post shows how to bind-mount the UI assets into the API gateway as a separate container.\n\n\nRemove the Docker stack, then re-define the faas network as \"attachable\":\n\n\n$ docker stack rm func\n$ docker network create func_functions --driver=overlay --attachable=true\n\n\n\n\nNow edit the \ndocker-compose.yml\n file and replace the existing networks block with:\n\n\nnetworks:\n    functions:\n        external:\n            name: func_functions\n\n\n\n\nNow deploy the rest of the stack with: \n./deploy_stack.sh\n.\n\n\nNow you can run the gateway as its own container via \ndocker run\n and bind-mount in the HTML assets.\n\n\n$ docker service rm func_gateway\n$ docker run --name func_gateway -v `pwd`/gateway/assets:/root/assets \\\n  -v \n/var/run/docker.sock:/var/run/docker.sock\n \\\n  -p 8080:8080 --network=func_functions \\\n  -d functions/gateway:latest-dev", 
            "title": "API Gateway"
        }, 
        {
            "location": "/developer/gateway/#api-gateway", 
            "text": "To work on the OpenFaaS API Gateway component checkout the \"./build.sh\" scripts and acompanying Dockerfiles.   Roadmap and Contributing", 
            "title": "API Gateway"
        }, 
        {
            "location": "/developer/gateway/#build-a-development-api-gateway", 
            "text": "Build a new development Docker image:   $ cd gateway/\n$ ./build.sh  This creates a Docker image with the name  functions/gateway:latest-dev , but if you want to use something else then pass the tag as an argument to the  ./build.sh  script. I.e.  ./build.sh labels-pr .    Now edit the Docker image for the  gateway  service in your  docker-compose.yml  file.    Redeploy the stack.    Test. Repeat.", 
            "title": "Build a development API Gateway"
        }, 
        {
            "location": "/developer/gateway/#work-on-the-ui-the-quick-way", 
            "text": "Working on the UI with the procedure above could take up to a minute to iterate between changing code and testing the changes. This section of the post shows how to bind-mount the UI assets into the API gateway as a separate container.  Remove the Docker stack, then re-define the faas network as \"attachable\":  $ docker stack rm func\n$ docker network create func_functions --driver=overlay --attachable=true  Now edit the  docker-compose.yml  file and replace the existing networks block with:  networks:\n    functions:\n        external:\n            name: func_functions  Now deploy the rest of the stack with:  ./deploy_stack.sh .  Now you can run the gateway as its own container via  docker run  and bind-mount in the HTML assets.  $ docker service rm func_gateway\n$ docker run --name func_gateway -v `pwd`/gateway/assets:/root/assets \\\n  -v  /var/run/docker.sock:/var/run/docker.sock  \\\n  -p 8080:8080 --network=func_functions \\\n  -d functions/gateway:latest-dev", 
            "title": "Work on the UI the quick way"
        }, 
        {
            "location": "/developer/dashboard/", 
            "text": "API Gateway Dashboard UI\n\n\nBuild a development UI for the API Gateway\n\n\nTo hack on the UI without rebuilding the gateway mount the assets in a bind-mount like this:\n\n\nRemove the Docker stack, then create the faas network as \"attachable\":\n\n\n$ docker stack rm func\n$ docker network create func_functions --driver=overlay --attachable=true\n\n\n\n\nNow edit the \ndocker-compose.yml\n file and replace the existing networks block with:\n\n\nnetworks:\n    functions:\n        external:\n            name: func_functions\n\n\n\n\nNow you can run the gateway as its own container and bind-mount in the HTML assets.\n\n\n$ docker run -v `pwd`/gateway/assets:/root/assets \\\n             -v \n/var/run/docker.sock:/var/run/docker.sock\n \\\n             -p 8080:8080 \\\n             --network=func_functions \\\n             -d functions/gateway:latest-dev\n\n\n\n\nNow deploy the rest of the stack with: \n./deploy_stack.sh\n.", 
            "title": "Dashboard UI"
        }, 
        {
            "location": "/developer/dashboard/#api-gateway-dashboard-ui", 
            "text": "", 
            "title": "API Gateway Dashboard UI"
        }, 
        {
            "location": "/developer/dashboard/#build-a-development-ui-for-the-api-gateway", 
            "text": "To hack on the UI without rebuilding the gateway mount the assets in a bind-mount like this:  Remove the Docker stack, then create the faas network as \"attachable\":  $ docker stack rm func\n$ docker network create func_functions --driver=overlay --attachable=true  Now edit the  docker-compose.yml  file and replace the existing networks block with:  networks:\n    functions:\n        external:\n            name: func_functions  Now you can run the gateway as its own container and bind-mount in the HTML assets.  $ docker run -v `pwd`/gateway/assets:/root/assets \\\n             -v  /var/run/docker.sock:/var/run/docker.sock  \\\n             -p 8080:8080 \\\n             --network=func_functions \\\n             -d functions/gateway:latest-dev  Now deploy the rest of the stack with:  ./deploy_stack.sh .", 
            "title": "Build a development UI for the API Gateway"
        }, 
        {
            "location": "/developer/watchdog/", 
            "text": "Watchdog\n\n\nThe watchdog provides an unmanaged and generic interface between the outside world and your function. Its job is to marshal a HTTP request accepted on the API Gateway and to invoke your chosen appliaction. The watchdog is a tiny Golang webserver - see the diagram below for how this process works.\n\n\n\n\n\n\nAbove: a tiny web-server or shim that forks your desired process for every incoming HTTP request\n\n\n\n\nEvery function needs to embed this binary and use it as its \nENTRYPOINT\n or \nCMD\n, in effect it is the init process for your container. Once your process is forked the watchdog passses in the HTTP request via \nstdin\n and reads a HTTP response via \nstdout\n. This means your process does not need to know anything about the web or HTTP.\n\n\nCreate a new function the easy way\n\n\nCreate a function via the CLI\n\n\nThe easiest way to create a function is to use a template and the FaaS CLI. The CLI allows you to abstract all Docker knowledge away, you just have to write a handler file in one of the supported programming languages.\n\n\n\n\n\n\nYour first serverless Python function with OpenFaaS\n\n\n\n\n\n\nRead a tutorial on the FaaS CLI\n\n\n\n\n\n\nPackage your function\n\n\nHere's how to package your function if you don't want to use the CLI or have existing binaries or images:\n\n\n\n\nUse an existing or a new Docker image as base image \nFROM\n\n\nAdd the fwatchdog binary from the \nReleases page\n via \ncurl\n or \nADD https://\n\n\nSet an \nfprocess\n environmental variable with the function you want to run for each request\n\n\nExpose port \n8080\n\n\nSet the \nCMD\n to \nfwatchdog\n\n\n\n\nExample Dockerfile for an \necho\n function:\n\n\nFROM alpine:3.5\n\nADD https://github.com/openfaas/faas/releases/download/v0.5-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\n# Define your UNIX binary here\nENV fprocess=\n/bin/cat\n\n\nCMD [\nfwatchdog\n]\n\n\n\n\nImplementing a Docker Healthcheck\n\n\nA Docker Healthcheck is not required but is best practice. It will make sure that the watchdog is ready to accept a request before forwarding requests via the API Gateway. If the function or watchdog runs into an unrecoverable issue Swarm will also be able to restart the container.\n\n\nHere is an example of the \necho\n function implementing a healthcheck with a 5-second checking interval.\n\n\nFROM functions/alpine\n\nENV fprocess=\ncat /etc/hostname\n\n\nHEALTHCHECK --interval=5s CMD [ -e /tmp/.lock ] || exit 1\n\n\n\n\nThe watchdog process creates a .lock file in \n/tmp/\n on starting its internal Golang HTTP server. \n[ -e file_name ]\n is shell to check if a file exists. With Windows Containers this is an invalid path so you may want to set the \nsuppress_lock\n environmental variable.\n\n\nRead my Docker Swarm tutorial on Healthchecks:\n\n\n\n\nTest-drive Docker Healthcheck in 10 minutes\n\n\n\n\nEnvironmental Overrides:\n\n\nThe watchdog can be configured through environmental variables. You must always specifiy an \nfprocess\n variable.\n\n\n\n\n\n\n\n\nOption\n\n\nUsage\n\n\n\n\n\n\n\n\n\n\nfprocess\n\n\nThe process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.\n\n\n\n\n\n\ncgi_headers\n\n\nHTTP headers from request are made available through environmental variables - \nHttp_X_Served_By\n etc. See section: \nHandling headers\n for more detail. Enabled by default.\n\n\n\n\n\n\nmarshal_requests\n\n\nInstead of re-directing the raw HTTP body into your fprocess, it will first be marshalled into JSON. Use this if you need to work with HTTP headers and do not want to use environmental variables via the \ncgi_headers\n flag.\n\n\n\n\n\n\ncontent_type\n\n\nForce a specific Content-Type response for all responses.\n\n\n\n\n\n\nwrite_timeout\n\n\nHTTP timeout for writing a response body from your function (in seconds)\n\n\n\n\n\n\nread_timeout\n\n\nHTTP timeout for reading the payload from the client caller (in seconds)\n\n\n\n\n\n\nsuppress_lock\n\n\nThe watchdog will attempt to write a lockfile to /tmp/ for swarm healthchecks - set this to true to disable behaviour.\n\n\n\n\n\n\nexec_timeout\n\n\nHard timeout for process exec'd for each incoming request (in seconds). Disabled if set to 0.\n\n\n\n\n\n\nwrite_debug\n\n\nWrite all output, error messages, and additional information to the logs. Default is false.\n\n\n\n\n\n\n\n\nAdvanced / Tuning\n\n\nWorking with HTTP Headers\n\n\nHeaders and other request information are injected into environmental variables in the following format:\n\n\nThe \nX-Forwarded-By\n header becomes available as \nHttp_X_Forwarded_By\n\n\n\n\nHttp_Method\n - GET/POST etc\n\n\nHttp_Query\n - QueryString value\n\n\nHttp_ContentLength\n - gives the total content-length of the incoming HTTP request received by the watchdog.\n\n\n\n\n\n\nThis behaviour is enabled by the \ncgi_headers\n environmental variable which is enabled by default.\n\n\n\n\nHere's an example of a POST request with an additional header and a query-string.\n\n\n$ cgi_headers=true fprocess=env ./watchdog \n\n2017/06/23 17:02:58 Writing lock-file to: /tmp/.lock\n\n$ curl -X POST \nlocalhost:8080?q=serverless\npage=1\n \\\n    -H X-Forwarded-By:http://my.vpn.com\n\n\n\n\nThis is what you'd see if you had set your \nfprocess\n to \nenv\n on a Linux system:\n\n\nHttp_User_Agent=curl/7.43.0\nHttp_Accept=*/*\nHttp_X_Forwarded_By=http://my.vpn.com\nHttp_Method=POST\nHttp_Query=q=serverless\npage=1\n\n\n\n\nYou can also use the \nGET\n verb:\n\n\n$ curl \nlocalhost:8080?action=quote\nqty=1\nproductId=105\n\n\n\n\n\nThe output from the watchdog would be:\n\n\nHttp_User_Agent=curl/7.43.0\nHttp_Accept=*/*\nHttp_Method=GET\nHttp_Query=action=quote\nqty=1\nproductId=105\n\n\n\n\nYou can now use HTTP state from within your application to make decisions.\n\n\nHTTP Methods\n\n\nThe HTTP methods supported for the watchdog are:\n\n\nWith a body:\n* \nPOST\n, \nPUT\n, \nDELETE\n, \nUPDATE\n\n\nWithout a body:\n* \nGET\n\n\n\n\nInfo\n\n\nThe API Gateway currently supports the POST route for functions.\n\n\n\n\nContent-Type of Request/Response\n\n\nBy default the watchdog will match the response of your function to the \"Content-Type\" of the client.\n\n\n\n\nIf your client sends a JSON post with a Content-Type of \napplication/json\n this will be matched automatically in the response.\n\n\nIf your client sends a JSON post with a Content-Type of \ntext/plain\n this will be matched automatically in the response too\n\n\n\n\nTo override the Content-Type of all your responses set the \ncontent_type\n environmental variable.\n\n\nI don't want to use the watchdog\n\n\nThis is an unsupported use-case for the OpenFaaS project however if your container exposes HTTP POST on port \n8080\n then the OpenFaaS API gateway and other tooling will manage your container.\n\n\nTuning Auto-scaling\n\n\nAuto-scaling starts at 1 replica and steps up in blocks of 5:\n\n\n\n\n1-\n5\n\n\n5-\n10\n\n\n10-\n15\n\n\n15-\n20\n\n\n\n\nYou can override the upper limit of auto-scaling by setting the following label on your container:\n\n\ncom.faas.max_replicas: \n10\n\n\n\n\n\nIf you want to disable scaling, set the \ncom.faas.max_replicas\n value to \n1\n.\n\n\nContribute to the Watchdog\n\n\nTo contribute to the OpenFaaS Watchdog component checkout the \"./build.sh\" scripts and acompanying Dockerfiles.\n\n\n\n\nRoadmap and Contributing", 
            "title": "Watchdog"
        }, 
        {
            "location": "/developer/watchdog/#watchdog", 
            "text": "The watchdog provides an unmanaged and generic interface between the outside world and your function. Its job is to marshal a HTTP request accepted on the API Gateway and to invoke your chosen appliaction. The watchdog is a tiny Golang webserver - see the diagram below for how this process works.    Above: a tiny web-server or shim that forks your desired process for every incoming HTTP request   Every function needs to embed this binary and use it as its  ENTRYPOINT  or  CMD , in effect it is the init process for your container. Once your process is forked the watchdog passses in the HTTP request via  stdin  and reads a HTTP response via  stdout . This means your process does not need to know anything about the web or HTTP.", 
            "title": "Watchdog"
        }, 
        {
            "location": "/developer/watchdog/#create-a-new-function-the-easy-way", 
            "text": "Create a function via the CLI  The easiest way to create a function is to use a template and the FaaS CLI. The CLI allows you to abstract all Docker knowledge away, you just have to write a handler file in one of the supported programming languages.    Your first serverless Python function with OpenFaaS    Read a tutorial on the FaaS CLI", 
            "title": "Create a new function the easy way"
        }, 
        {
            "location": "/developer/watchdog/#package-your-function", 
            "text": "Here's how to package your function if you don't want to use the CLI or have existing binaries or images:   Use an existing or a new Docker image as base image  FROM  Add the fwatchdog binary from the  Releases page  via  curl  or  ADD https://  Set an  fprocess  environmental variable with the function you want to run for each request  Expose port  8080  Set the  CMD  to  fwatchdog   Example Dockerfile for an  echo  function:  FROM alpine:3.5\n\nADD https://github.com/openfaas/faas/releases/download/v0.5-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\n# Define your UNIX binary here\nENV fprocess= /bin/cat \n\nCMD [ fwatchdog ]", 
            "title": "Package your function"
        }, 
        {
            "location": "/developer/watchdog/#implementing-a-docker-healthcheck", 
            "text": "A Docker Healthcheck is not required but is best practice. It will make sure that the watchdog is ready to accept a request before forwarding requests via the API Gateway. If the function or watchdog runs into an unrecoverable issue Swarm will also be able to restart the container.  Here is an example of the  echo  function implementing a healthcheck with a 5-second checking interval.  FROM functions/alpine\n\nENV fprocess= cat /etc/hostname \n\nHEALTHCHECK --interval=5s CMD [ -e /tmp/.lock ] || exit 1  The watchdog process creates a .lock file in  /tmp/  on starting its internal Golang HTTP server.  [ -e file_name ]  is shell to check if a file exists. With Windows Containers this is an invalid path so you may want to set the  suppress_lock  environmental variable.  Read my Docker Swarm tutorial on Healthchecks:   Test-drive Docker Healthcheck in 10 minutes", 
            "title": "Implementing a Docker Healthcheck"
        }, 
        {
            "location": "/developer/watchdog/#environmental-overrides", 
            "text": "The watchdog can be configured through environmental variables. You must always specifiy an  fprocess  variable.     Option  Usage      fprocess  The process to invoke for each function call. This must be a UNIX binary and accept input via STDIN and output via STDOUT.    cgi_headers  HTTP headers from request are made available through environmental variables -  Http_X_Served_By  etc. See section:  Handling headers  for more detail. Enabled by default.    marshal_requests  Instead of re-directing the raw HTTP body into your fprocess, it will first be marshalled into JSON. Use this if you need to work with HTTP headers and do not want to use environmental variables via the  cgi_headers  flag.    content_type  Force a specific Content-Type response for all responses.    write_timeout  HTTP timeout for writing a response body from your function (in seconds)    read_timeout  HTTP timeout for reading the payload from the client caller (in seconds)    suppress_lock  The watchdog will attempt to write a lockfile to /tmp/ for swarm healthchecks - set this to true to disable behaviour.    exec_timeout  Hard timeout for process exec'd for each incoming request (in seconds). Disabled if set to 0.    write_debug  Write all output, error messages, and additional information to the logs. Default is false.", 
            "title": "Environmental Overrides:"
        }, 
        {
            "location": "/developer/watchdog/#advanced-tuning", 
            "text": "", 
            "title": "Advanced / Tuning"
        }, 
        {
            "location": "/developer/watchdog/#working-with-http-headers", 
            "text": "Headers and other request information are injected into environmental variables in the following format:  The  X-Forwarded-By  header becomes available as  Http_X_Forwarded_By   Http_Method  - GET/POST etc  Http_Query  - QueryString value  Http_ContentLength  - gives the total content-length of the incoming HTTP request received by the watchdog.    This behaviour is enabled by the  cgi_headers  environmental variable which is enabled by default.   Here's an example of a POST request with an additional header and a query-string.  $ cgi_headers=true fprocess=env ./watchdog  \n2017/06/23 17:02:58 Writing lock-file to: /tmp/.lock\n\n$ curl -X POST  localhost:8080?q=serverless page=1  \\\n    -H X-Forwarded-By:http://my.vpn.com  This is what you'd see if you had set your  fprocess  to  env  on a Linux system:  Http_User_Agent=curl/7.43.0\nHttp_Accept=*/*\nHttp_X_Forwarded_By=http://my.vpn.com\nHttp_Method=POST\nHttp_Query=q=serverless page=1  You can also use the  GET  verb:  $ curl  localhost:8080?action=quote qty=1 productId=105   The output from the watchdog would be:  Http_User_Agent=curl/7.43.0\nHttp_Accept=*/*\nHttp_Method=GET\nHttp_Query=action=quote qty=1 productId=105  You can now use HTTP state from within your application to make decisions.", 
            "title": "Working with HTTP Headers"
        }, 
        {
            "location": "/developer/watchdog/#http-methods", 
            "text": "The HTTP methods supported for the watchdog are:  With a body:\n*  POST ,  PUT ,  DELETE ,  UPDATE  Without a body:\n*  GET   Info  The API Gateway currently supports the POST route for functions.", 
            "title": "HTTP Methods"
        }, 
        {
            "location": "/developer/watchdog/#content-type-of-requestresponse", 
            "text": "By default the watchdog will match the response of your function to the \"Content-Type\" of the client.   If your client sends a JSON post with a Content-Type of  application/json  this will be matched automatically in the response.  If your client sends a JSON post with a Content-Type of  text/plain  this will be matched automatically in the response too   To override the Content-Type of all your responses set the  content_type  environmental variable.", 
            "title": "Content-Type of Request/Response"
        }, 
        {
            "location": "/developer/watchdog/#i-dont-want-to-use-the-watchdog", 
            "text": "This is an unsupported use-case for the OpenFaaS project however if your container exposes HTTP POST on port  8080  then the OpenFaaS API gateway and other tooling will manage your container.", 
            "title": "I don't want to use the watchdog"
        }, 
        {
            "location": "/developer/watchdog/#tuning-auto-scaling", 
            "text": "Auto-scaling starts at 1 replica and steps up in blocks of 5:   1- 5  5- 10  10- 15  15- 20   You can override the upper limit of auto-scaling by setting the following label on your container:  com.faas.max_replicas:  10   If you want to disable scaling, set the  com.faas.max_replicas  value to  1 .", 
            "title": "Tuning Auto-scaling"
        }, 
        {
            "location": "/developer/watchdog/#contribute-to-the-watchdog", 
            "text": "To contribute to the OpenFaaS Watchdog component checkout the \"./build.sh\" scripts and acompanying Dockerfiles.   Roadmap and Contributing", 
            "title": "Contribute to the Watchdog"
        }, 
        {
            "location": "/developer/functions/", 
            "text": "Functions\n\n\nCreating a function\n\n\nFunctions run as Docker containers with the Watchdog component embedded to handle communication with the API Gateway.\n\n\nYou can find the \nreference documentation for the Watchdog here\n.\n\n\nMarkdown Parser\n\n\nThis is the basis of a function which generates HTML from MarkDown:\n\n\nFROM golang:1.7.5\nRUN mkdir -p /go/src/app\nCOPY handler.go /go/src/app\nWORKDIR /go/src/app\nRUN go get github.com/microcosm-cc/bluemonday \n \\\n    go get github.com/russross/blackfriday\n\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n\nADD https://github.com/openfaas/faas/releases/download/v0.3-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\nENV fprocess=\n/go/src/app/app\n\n\nCMD [\n/usr/bin/fwatchdog\n]\n\n\n\n\nThe base Docker container is not important, you just need to add the watchdog component and then set the fprocess to execute your binary at runtime.\n\n\nUpdate the Docker stack with this:\n\n\n    markdown:\n        image: alexellis2/faas-markdownrender:latest\n        labels:\n            function: \ntrue\n\n        depends_on:\n            - gateway\n        networks:\n            - functions\n\n\n\n\nWord counter with busybox\n\n\nFROM alpine:latest\n\nADD https://github.com/openfaas/faas/releases/download/v0.3-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\nENV fprocess=\nwc\n\nCMD [\nfwatchdog\n]\n\n\n\n\nUpdate your Docker stack with this definition:\n\n\n    wordcount:\n        image: alexellis2/faas-alpinefunction:latest\n        labels:\n            function: \ntrue\n\n        depends_on:\n            - gateway\n        networks:\n            - functions\n        environment:\n            fprocess:   \nwc\n\n\n\n\n\nTesting your function\n\n\nYou can test your function through a webbrowser against the UI portal on port 8080.\n\n\nhttp://localhost:8080/\n\n\nYou can also invoke a function by name with curl:\n\n\ncurl --data-binary @README.md http://localhost:8080/function/func_wordcount\n\n\n\n\nAsynchronous processing\n\n\nBy default functions are accessed synchronously via the following route:\n\n\n$ curl --data \nmessage\n http://gateway/function/{function_name}\n\n\n\n\nAs of \nPR #131\n asynchronous invocation is available for testing.\n\n\nLogical flow for synchronous functions:\n\n\n\n\nWhy use Asynchronous processing?\n\n\n\n\n\n\nEnable longer time-outs\n\n\n\n\n\n\nProcess work whenever resources are available rather than immediately\n\n\n\n\n\n\nConsume a large batch of work within a few seconds and let it process at its own pace\n\n\n\n\n\n\nHow does async work?\n\n\nHere is a conceptual diagram\n\n\n\n\n\n\nqueue-worker\n\n\n\n\nDeploy the async stack\n\n\nThe reference implementation for asychronous processing uses NATS Streaming, but you are free to extend OpenFaaS and write your own \nqueue-worker\n.\n\n\nSwarm:\n\n\n$ ./deploy_extended.sh\n\n\n\n\nK8s:\n\n\n$ kubectl -f delete ./faas.yml\n$ kubectl -f apply ./faas.async.yml,nats.yml\n\n\n\n\nCall a function\n\n\nFunctions do not need to be modified to work asynchronously, just use this alternate route:\n\n\n$ http://gateway/async-function/{function_name}\n\n\n\n\nIf you want the function to call another function or a different endpoint when it is finished then pass the \nX-Callback-Url\n header. This is optional.\n\n\n$ curl http://gateway/async-function/{function_name} \\\n    -H \nX-Callback-Url: http://gateway/function/send2slack\n \\\n    --data-binary @sample.json\n\n\n\n\nExtend function timeouts\n\n\nFunctions have three timeouts configurable by environmental variables expressed in seconds:\n\n\nHTTP:\n\n\n\n\nread_timeout\n\n\nwrite_timeout\n\n\n\n\nHard timeout:\n\n\n\n\nexec_timeout\n\n\n\n\nTo make use of these just add them to your Dockerfile when needed as ENV variables.\n\n\n\n\nFunction watchdog reference", 
            "title": "Functions"
        }, 
        {
            "location": "/developer/functions/#functions", 
            "text": "", 
            "title": "Functions"
        }, 
        {
            "location": "/developer/functions/#creating-a-function", 
            "text": "Functions run as Docker containers with the Watchdog component embedded to handle communication with the API Gateway.  You can find the  reference documentation for the Watchdog here .  Markdown Parser  This is the basis of a function which generates HTML from MarkDown:  FROM golang:1.7.5\nRUN mkdir -p /go/src/app\nCOPY handler.go /go/src/app\nWORKDIR /go/src/app\nRUN go get github.com/microcosm-cc/bluemonday   \\\n    go get github.com/russross/blackfriday\n\nRUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .\n\nADD https://github.com/openfaas/faas/releases/download/v0.3-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\nENV fprocess= /go/src/app/app \n\nCMD [ /usr/bin/fwatchdog ]  The base Docker container is not important, you just need to add the watchdog component and then set the fprocess to execute your binary at runtime.  Update the Docker stack with this:      markdown:\n        image: alexellis2/faas-markdownrender:latest\n        labels:\n            function:  true \n        depends_on:\n            - gateway\n        networks:\n            - functions  Word counter with busybox  FROM alpine:latest\n\nADD https://github.com/openfaas/faas/releases/download/v0.3-alpha/fwatchdog /usr/bin\nRUN chmod +x /usr/bin/fwatchdog\n\nENV fprocess= wc \nCMD [ fwatchdog ]  Update your Docker stack with this definition:      wordcount:\n        image: alexellis2/faas-alpinefunction:latest\n        labels:\n            function:  true \n        depends_on:\n            - gateway\n        networks:\n            - functions\n        environment:\n            fprocess:    wc", 
            "title": "Creating a function"
        }, 
        {
            "location": "/developer/functions/#testing-your-function", 
            "text": "You can test your function through a webbrowser against the UI portal on port 8080.  http://localhost:8080/  You can also invoke a function by name with curl:  curl --data-binary @README.md http://localhost:8080/function/func_wordcount", 
            "title": "Testing your function"
        }, 
        {
            "location": "/developer/functions/#asynchronous-processing", 
            "text": "By default functions are accessed synchronously via the following route:  $ curl --data  message  http://gateway/function/{function_name}  As of  PR #131  asynchronous invocation is available for testing.  Logical flow for synchronous functions:", 
            "title": "Asynchronous processing"
        }, 
        {
            "location": "/developer/functions/#why-use-asynchronous-processing", 
            "text": "Enable longer time-outs    Process work whenever resources are available rather than immediately    Consume a large batch of work within a few seconds and let it process at its own pace", 
            "title": "Why use Asynchronous processing?"
        }, 
        {
            "location": "/developer/functions/#how-does-async-work", 
            "text": "Here is a conceptual diagram    queue-worker", 
            "title": "How does async work?"
        }, 
        {
            "location": "/developer/functions/#deploy-the-async-stack", 
            "text": "The reference implementation for asychronous processing uses NATS Streaming, but you are free to extend OpenFaaS and write your own  queue-worker .  Swarm:  $ ./deploy_extended.sh  K8s:  $ kubectl -f delete ./faas.yml\n$ kubectl -f apply ./faas.async.yml,nats.yml", 
            "title": "Deploy the async stack"
        }, 
        {
            "location": "/developer/functions/#call-a-function", 
            "text": "Functions do not need to be modified to work asynchronously, just use this alternate route:  $ http://gateway/async-function/{function_name}  If you want the function to call another function or a different endpoint when it is finished then pass the  X-Callback-Url  header. This is optional.  $ curl http://gateway/async-function/{function_name} \\\n    -H  X-Callback-Url: http://gateway/function/send2slack  \\\n    --data-binary @sample.json", 
            "title": "Call a function"
        }, 
        {
            "location": "/developer/functions/#extend-function-timeouts", 
            "text": "Functions have three timeouts configurable by environmental variables expressed in seconds:  HTTP:   read_timeout  write_timeout   Hard timeout:   exec_timeout   To make use of these just add them to your Dockerfile when needed as ENV variables.   Function watchdog reference", 
            "title": "Extend function timeouts"
        }, 
        {
            "location": "/developer/asynchronous/", 
            "text": "Guide on Asynchronous processing\n\n\nBy default functions are accessed synchronously via the following route:\n\n\n$ curl --data \nmessage\n http://gateway/function/{function_name}\n\n\n\n\nAs of \nPR #131\n asynchronous invocation is available for testing.\n\n\nLogical flow for synchronous functions:\n\n\n\n\nWhy use Asynchronous processing?\n\n\n\n\n\n\nEnable longer time-outs\n\n\n\n\n\n\nProcess work whenever resources are available rather than immediately\n\n\n\n\n\n\nConsume a large batch of work within a few seconds and let it process at its own pace\n\n\n\n\n\n\nHow does async work?\n\n\nHere is a conceptual diagram\n\n\n\n\nYou can also use asynchronous calls with a callback URL\n\n\n\n\nDeploy the async stack\n\n\nThe reference implementation for asychronous processing uses NATS Streaming, but you are free to extend OpenFaaS and write your own \nqueue-worker\n.\n\n\nSwarm:\n\n\n$ ./deploy_extended.sh\n\n\n\n\nK8s:\n\n\n$ kubectl -f delete ./faas.yml\n$ kubectl -f apply ./faas.async.yml,nats.yml\n\n\n\n\nCall a function\n\n\nFunctions do not need to be modified to work asynchronously, just use this alternate route:\n\n\n$ http://gateway/async-function/{function_name}\n\n\n\n\nIf you want the function to call another function or a different endpoint when it is finished then pass the \nX-Callback-Url\n header. This is optional.\n\n\n$ curl http://gateway/async-function/{function_name} --data-binary @sample.json -H \nX-Callback-Url: http://gateway/function/send2slack\n\n\n\n\n\nExtend function timeouts\n\n\nFunctions have three timeouts configurable by environmental variables expressed in seconds:\n\n\nHTTP:\n\n\n\n\nread_timeout\n\n\nwrite_timeout\n\n\n\n\nHard timeout:\n\n\n\n\nexec_timeout\n\n\n\n\nTo make use of these just add them to your Dockerfile when needed as ENV variables.\n\n\n\n\nFunction watchdog reference", 
            "title": "Asynchronous Functions"
        }, 
        {
            "location": "/developer/asynchronous/#guide-on-asynchronous-processing", 
            "text": "By default functions are accessed synchronously via the following route:  $ curl --data  message  http://gateway/function/{function_name}  As of  PR #131  asynchronous invocation is available for testing.  Logical flow for synchronous functions:", 
            "title": "Guide on Asynchronous processing"
        }, 
        {
            "location": "/developer/asynchronous/#why-use-asynchronous-processing", 
            "text": "Enable longer time-outs    Process work whenever resources are available rather than immediately    Consume a large batch of work within a few seconds and let it process at its own pace", 
            "title": "Why use Asynchronous processing?"
        }, 
        {
            "location": "/developer/asynchronous/#how-does-async-work", 
            "text": "Here is a conceptual diagram   You can also use asynchronous calls with a callback URL", 
            "title": "How does async work?"
        }, 
        {
            "location": "/developer/asynchronous/#deploy-the-async-stack", 
            "text": "The reference implementation for asychronous processing uses NATS Streaming, but you are free to extend OpenFaaS and write your own  queue-worker .  Swarm:  $ ./deploy_extended.sh  K8s:  $ kubectl -f delete ./faas.yml\n$ kubectl -f apply ./faas.async.yml,nats.yml", 
            "title": "Deploy the async stack"
        }, 
        {
            "location": "/developer/asynchronous/#call-a-function", 
            "text": "Functions do not need to be modified to work asynchronously, just use this alternate route:  $ http://gateway/async-function/{function_name}  If you want the function to call another function or a different endpoint when it is finished then pass the  X-Callback-Url  header. This is optional.  $ curl http://gateway/async-function/{function_name} --data-binary @sample.json -H  X-Callback-Url: http://gateway/function/send2slack", 
            "title": "Call a function"
        }, 
        {
            "location": "/developer/asynchronous/#extend-function-timeouts", 
            "text": "Functions have three timeouts configurable by environmental variables expressed in seconds:  HTTP:   read_timeout  write_timeout   Hard timeout:   exec_timeout   To make use of these just add them to your Dockerfile when needed as ENV variables.   Function watchdog reference", 
            "title": "Extend function timeouts"
        }, 
        {
            "location": "/developer/swagger/", 
            "text": "Swagger API\n\n\nExploring or editing the Swagger API documentation\n\n\nThe \nswagger.yml\n file can be viewed and edited in the Swagger UI.\n\n\n\n\n\n\nHead over to the \nSwagger editor\n\n\n\n\n\n\nNow click File -\n Import URL\n\n\n\n\n\n\nType in \nhttps://raw.githubusercontent.com/openfaas/faas/master/api-docs/swagger.yml\n and click OK\n\n\n\n\n\n\nYou can now view and edit the Swagger, copy back to your fork before pushing changes.", 
            "title": "Swagger API"
        }, 
        {
            "location": "/developer/swagger/#swagger-api", 
            "text": "", 
            "title": "Swagger API"
        }, 
        {
            "location": "/developer/swagger/#exploring-or-editing-the-swagger-api-documentation", 
            "text": "The  swagger.yml  file can be viewed and edited in the Swagger UI.    Head over to the  Swagger editor    Now click File -  Import URL    Type in  https://raw.githubusercontent.com/openfaas/faas/master/api-docs/swagger.yml  and click OK    You can now view and edit the Swagger, copy back to your fork before pushing changes.", 
            "title": "Exploring or editing the Swagger API documentation"
        }, 
        {
            "location": "/developer/debug/", 
            "text": "Debug information\n\n\nThis is a useful Prometheus query to show:\n\n\n\n\nService replicas\n\n\nRate of invocation\n\n\nExecution time of events\n\n\n\n\nhttp://localhost:9090/graph?g0.range_input=15m\ng0.expr=gateway_service_count\ng0.tab=0\ng1.range_input=15m\ng1.expr=rate(gateway_function_invocation_total%5B20s%5D)\ng1.tab=0\ng2.range_input=15m\ng2.expr=gateway_functions_seconds_sum+%2F+gateway_functions_seconds_count\ng2.tab=0\n\n\n$ docker service ls -q | \\\n  xargs -n 1 -I {} docker service scale {}=10; \\\n  docker service scale func_gateway=1 ;\n\n$ docker service scale func_prometheus=1 ; \\\n  docker service scale func_alertmanager=1", 
            "title": "Debugging"
        }, 
        {
            "location": "/developer/debug/#debug-information", 
            "text": "This is a useful Prometheus query to show:   Service replicas  Rate of invocation  Execution time of events   http://localhost:9090/graph?g0.range_input=15m g0.expr=gateway_service_count g0.tab=0 g1.range_input=15m g1.expr=rate(gateway_function_invocation_total%5B20s%5D) g1.tab=0 g2.range_input=15m g2.expr=gateway_functions_seconds_sum+%2F+gateway_functions_seconds_count g2.tab=0  $ docker service ls -q | \\\n  xargs -n 1 -I {} docker service scale {}=10; \\\n  docker service scale func_gateway=1 ;\n\n$ docker service scale func_prometheus=1 ; \\\n  docker service scale func_alertmanager=1", 
            "title": "Debug information"
        }, 
        {
            "location": "/developer/backends/", 
            "text": "OpenFaaS backends guide\n\n\nOpenFaaS is a framework for building serverless functions with containers and running them at scale.\n\n\n\n\nBring Serverless OpenFaaS functions to your favourite container platform.\n\n\n\n\nWe support two orchestration platforms or \"backends\":\n\n\n\n\nDocker Swarm\n\n\nKubernetes\n\n\n\n\nThere is also community work in-progress to support:\n\n\n\n\nRancher/Cattle\n\n\n\n\nThe Docker Swarm support is built-into the faas repo, but the Kubernetes support is provided by a microservice in the \nfaas-netes\n repo.\n\n\nIf you're thinking of writing a new back-end we'd love to hear about it and help you, so please get in touch with \n. Existing implementations (like OpenFaaS) are written in Golang and this provides a level of consistency across the projects.\n\n\nI need a backend for X\n\n\nThis project is focusing on Docker Swarm and Kubernetes, but we're open to support from third parties and vendors for other backends:\n\n\nHere are some ideas:\n\n\n\n\nNomad\n\n\nMarathon Mesos\n\n\nAWS ECS\n\n\nHyper.sh\n\n\n\n\nIf you would like to write your own back-end for \nX\n then you can write your own microservice that conforms to the \nSwagger API\n here.\n\n\nHow does my back-end work?\n\n\nIn order to support a new back end you will write a new \"external_provider\" and configure this on the API Gateway. The API Gateway will then proxy any requests to your new microservice. The first \"external_provider\" was the Kubernetes implementation \nfaas-netes\n:\n\n\n\n\nDeploy a function - through the built-in Swarm support or through faas-netes\n\n\n\n\nInvoke your function - through the built-in Swarm or via faas-netes\n\n\n\n\nFind out more about the \nwatchdog here\n.\n\n\nAutomatically compatible OpenFaaS\n\n\nThe following are fully compatible with any additional back-ends:\n\n\n\n\nAPI Gateway\n\n\nPromethes metrics (tracked through API Gateway)\n\n\nThe built-in UI portal (hosted on the API Gateway)\n\n\nThe Function Watchdog and any existing OpenFaaS functions\n\n\nThe \nCLI\n\n\nAsynchronous function invocation\n\n\n\n\nDependent on back-end:\n\n\n\n\nSecrets or environmental variable support\n\n\nWindows Containers function runtimes (i.e. via W2016 and Docker)\n\n\nScaling - dependent on underlying API (available in Docker \n Kubernetes)\n\n\n\n\nBackend endpoints:\n\n\n\n\nList / Create / Delete a function\n\n\n\n\n/system/functions\n\n\nMethod(s): GET / POST / DELETE \n\n\n\n\nGet a specific function\n\n\n\n\n/system/function/{name:[-a-zA-Z_0-9]+}\n\n\nMethod(s): GET\n\n\n\n\nScale a specific function:\n\n\n\n\n/system/scale-function/{name:[-a-zA-Z_0-9]+}\n\n\nMethod(s): POST\n\n\n\n\nInvoke a specific function\n\n\n\n\n/function/{name:[-a-zA-Z_0-9]+}\n\n\nMethod(s): POST\n\n\nExamples / documentation\n\n\n\n\nSee the \nSwagger API\n as a starting point.\n\n\n\n\nfaas-netes (Kubernetes)\n\n\nThe Kubernetes integration was written by Alex Ellis and is officially supported by the project.\n\n\n\n\nSee the \nFaaS-netes handlers\n for examples of how to implement each endpoint.\n\n\n\n\nRancher / Cattle (community)\n\n\nThis work is by Ken Fukuyama from Japan.\n\n\n\n\n\n\nBlog post\n\n\n\n\n\n\nfaas-rancher\n implementation in Golang", 
            "title": "Backends"
        }, 
        {
            "location": "/developer/backends/#openfaas-backends-guide", 
            "text": "OpenFaaS is a framework for building serverless functions with containers and running them at scale.   Bring Serverless OpenFaaS functions to your favourite container platform.   We support two orchestration platforms or \"backends\":   Docker Swarm  Kubernetes   There is also community work in-progress to support:   Rancher/Cattle   The Docker Swarm support is built-into the faas repo, but the Kubernetes support is provided by a microservice in the  faas-netes  repo.  If you're thinking of writing a new back-end we'd love to hear about it and help you, so please get in touch with  . Existing implementations (like OpenFaaS) are written in Golang and this provides a level of consistency across the projects.", 
            "title": "OpenFaaS backends guide"
        }, 
        {
            "location": "/developer/backends/#i-need-a-backend-for-x", 
            "text": "This project is focusing on Docker Swarm and Kubernetes, but we're open to support from third parties and vendors for other backends:  Here are some ideas:   Nomad  Marathon Mesos  AWS ECS  Hyper.sh   If you would like to write your own back-end for  X  then you can write your own microservice that conforms to the  Swagger API  here.", 
            "title": "I need a backend for X"
        }, 
        {
            "location": "/developer/backends/#how-does-my-back-end-work", 
            "text": "In order to support a new back end you will write a new \"external_provider\" and configure this on the API Gateway. The API Gateway will then proxy any requests to your new microservice. The first \"external_provider\" was the Kubernetes implementation  faas-netes :   Deploy a function - through the built-in Swarm support or through faas-netes   Invoke your function - through the built-in Swarm or via faas-netes   Find out more about the  watchdog here .", 
            "title": "How does my back-end work?"
        }, 
        {
            "location": "/developer/backends/#automatically-compatible-openfaas", 
            "text": "The following are fully compatible with any additional back-ends:   API Gateway  Promethes metrics (tracked through API Gateway)  The built-in UI portal (hosted on the API Gateway)  The Function Watchdog and any existing OpenFaaS functions  The  CLI  Asynchronous function invocation   Dependent on back-end:   Secrets or environmental variable support  Windows Containers function runtimes (i.e. via W2016 and Docker)  Scaling - dependent on underlying API (available in Docker   Kubernetes)", 
            "title": "Automatically compatible OpenFaaS"
        }, 
        {
            "location": "/developer/backends/#backend-endpoints", 
            "text": "List / Create / Delete a function   /system/functions  Method(s): GET / POST / DELETE    Get a specific function   /system/function/{name:[-a-zA-Z_0-9]+}  Method(s): GET   Scale a specific function:   /system/scale-function/{name:[-a-zA-Z_0-9]+}  Method(s): POST   Invoke a specific function   /function/{name:[-a-zA-Z_0-9]+}  Method(s): POST", 
            "title": "Backend endpoints:"
        }, 
        {
            "location": "/developer/backends/#examples-documentation", 
            "text": "See the  Swagger API  as a starting point.", 
            "title": "Examples / documentation"
        }, 
        {
            "location": "/developer/backends/#faas-netes-kubernetes", 
            "text": "The Kubernetes integration was written by Alex Ellis and is officially supported by the project.   See the  FaaS-netes handlers  for examples of how to implement each endpoint.", 
            "title": "faas-netes (Kubernetes)"
        }, 
        {
            "location": "/developer/backends/#rancher-cattle-community", 
            "text": "This work is by Ken Fukuyama from Japan.    Blog post    faas-rancher  implementation in Golang", 
            "title": "Rancher / Cattle (community)"
        }, 
        {
            "location": "/developer/chaining_functions/", 
            "text": "Chaining OpenFaaS functions\n\n\nWe will discuss client-side piping, server-side piping and the \"function director\" pattern.\n\n\nClient-side piping\n\n\nThe easiest way to chain functions is to do it on the client-side via your application code or a \ncurl\n.\n\n\nHere is an example:\n\n\nWe pipe a string or file into the markdown function, then pipe it into a Slack function\n\n\n$ curl -d \n# test\n localhost:8080/function/markdown | \\\n  curl localhost:8080/function/slack --data-binary -\n\n\n\n\nYou could also do this via code, or through the \nfaas-cli\n:\n\n\n$ echo \ntest\n | faas-cli invoke markdown | \\\nfaas-cli invoke slack\n\n\n\n\nServer-side access via gateway\n\n\nOn the server side you can access any other function by calling it on the gateway over HTTP.\n\n\nFunction A calls B\n\n\nLet's say we have two functions:\n* geolocatecity - gives a city name for a lat/lon combo in JSON format\n* findiss - finds the location of the International Space Station then pretty-prints the city name by using the \ngeolocatecity\n function\n\n\nfindiss Python 2.7 handler:\n\n\nimport requests\n\ndef get_space_station_location():\n    return {\nlat\n: 0.51112, \nlon\n: -0.1234}\n\ndef handler(st):\n    location = get_space_station_location()\n    r = requests.post(\nhttp://gateway:8080/function/geolocatecity\n, location)\n\n    print(\nThe ISS is over the following city: \n + r.content)\n\n\n\n\nFunction Director pattern\n\n\nIn the Function Director pattern - we create a \"wrapper function\" which can then either pipes the result of function call A into function call B or compose the results of A and B before returning a result. This approach saves on bandwidth and latency vs. client-side piping and means you can version both your connector and the functions involved.\n\n\nTake our previous example:\n\n\n$ curl -d \n# test\n localhost:8080/function/markdown | \\\n  curl localhost:8080/function/slack --data-binary -\n\n\n\n\nmarkdown2slack Python 2.7 handler:\n\n\nimport requests\n\ndef handler(req):\n\n    markdown = requests.post(\nhttp://gateway:8080/function/markdown\n, req)\n    slack_result = requests.post(\nhttp://gateway:8080/function/slack\n, markdown.content)\n\n    print(\nSlack result: \n + str(slack_result.status_code))\n\n\n\n\nPractical example:\n\n\nGitHub sends a \"star\" event to tweetfanclub function, tweetfanclub uses get-avatar to download the user's profile picture - stores that in an S3 bucket, then invokes tweetstargazer which tweets the image. A polaroid effect is added by a \"polaroid\" function.\n\n\nThis example uses a mix of regular binaries such as ImageMagick and Python handlers generated with the FaaS-CLI.\n\n\n\n\nGitHub to Twitter Fanclub", 
            "title": "Function Chaining"
        }, 
        {
            "location": "/developer/chaining_functions/#chaining-openfaas-functions", 
            "text": "We will discuss client-side piping, server-side piping and the \"function director\" pattern.", 
            "title": "Chaining OpenFaaS functions"
        }, 
        {
            "location": "/developer/chaining_functions/#client-side-piping", 
            "text": "The easiest way to chain functions is to do it on the client-side via your application code or a  curl .  Here is an example:  We pipe a string or file into the markdown function, then pipe it into a Slack function  $ curl -d  # test  localhost:8080/function/markdown | \\\n  curl localhost:8080/function/slack --data-binary -  You could also do this via code, or through the  faas-cli :  $ echo  test  | faas-cli invoke markdown | \\\nfaas-cli invoke slack", 
            "title": "Client-side piping"
        }, 
        {
            "location": "/developer/chaining_functions/#server-side-access-via-gateway", 
            "text": "On the server side you can access any other function by calling it on the gateway over HTTP.", 
            "title": "Server-side access via gateway"
        }, 
        {
            "location": "/developer/chaining_functions/#function-a-calls-b", 
            "text": "Let's say we have two functions:\n* geolocatecity - gives a city name for a lat/lon combo in JSON format\n* findiss - finds the location of the International Space Station then pretty-prints the city name by using the  geolocatecity  function  findiss Python 2.7 handler:  import requests\n\ndef get_space_station_location():\n    return { lat : 0.51112,  lon : -0.1234}\n\ndef handler(st):\n    location = get_space_station_location()\n    r = requests.post( http://gateway:8080/function/geolocatecity , location)\n\n    print( The ISS is over the following city:   + r.content)", 
            "title": "Function A calls B"
        }, 
        {
            "location": "/developer/chaining_functions/#function-director-pattern", 
            "text": "In the Function Director pattern - we create a \"wrapper function\" which can then either pipes the result of function call A into function call B or compose the results of A and B before returning a result. This approach saves on bandwidth and latency vs. client-side piping and means you can version both your connector and the functions involved.  Take our previous example:  $ curl -d  # test  localhost:8080/function/markdown | \\\n  curl localhost:8080/function/slack --data-binary -  markdown2slack Python 2.7 handler:  import requests\n\ndef handler(req):\n\n    markdown = requests.post( http://gateway:8080/function/markdown , req)\n    slack_result = requests.post( http://gateway:8080/function/slack , markdown.content)\n\n    print( Slack result:   + str(slack_result.status_code))  Practical example:  GitHub sends a \"star\" event to tweetfanclub function, tweetfanclub uses get-avatar to download the user's profile picture - stores that in an S3 bucket, then invokes tweetstargazer which tweets the image. A polaroid effect is added by a \"polaroid\" function.  This example uses a mix of regular binaries such as ImageMagick and Python handlers generated with the FaaS-CLI.   GitHub to Twitter Fanclub", 
            "title": "Function Director pattern"
        }, 
        {
            "location": "/contributing/", 
            "text": "", 
            "title": "Contributing"
        }
    ]
}